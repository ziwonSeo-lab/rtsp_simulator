import cv2
import time
from datetime import datetime
import os
import argparse
from ultralytics import YOLO
import numpy as np

class HeadBlurrer:
    def __init__(self, model_path="best_re_final.engine", num_camera=1):
        """
        HeadBlurrer ì´ˆê¸°í™”
        
        Args:
            model_path (str): PyTorch ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        """
        self.model_path = model_path
        self.conf_threshold = 0.5  # íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model()
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        
        self.frame_counts = [0 for i in range(num_camera)]
        self.last_head_boxes = [[] for i in range(num_camera)]
    
    def _load_model(self):
        """PyTorch YOLO ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        try:
            model = YOLO(self.model_path)
            return model
        except Exception as e:
            raise RuntimeError(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
    def _detect_heads(self, image):
        """
        ë¨¸ë¦¬ íƒì§€ ìˆ˜í–‰
        

        Args:
            image: OpenCV ì´ë¯¸ì§€ (BGR)
        
        Returns:
            list: ë¨¸ë¦¬ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ [[x1,y1,x2,y2], ...]
        """
        try:
            # YOLO ì¶”ë¡  
            results = self.model(image, conf=self.conf_threshold, verbose=False)
            
            head_boxes = []
            if results[0].boxes is not None:
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ
                boxes = results[0].boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2] í˜•íƒœ
                for box in boxes:
                    x1, y1, x2, y2 = box.astype(int)
                    head_boxes.append([x1, y1, x2, y2])
            else:
                print("íƒì§€ëœ ë¨¸ë¦¬ ì—†ìŒ")
            
            return head_boxes
            
        except Exception as e:
            print(f"âš ï¸  ë¨¸ë¦¬ íƒì§€ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _apply_blur_to_heads(self, image, head_boxes, blur_strength=0.01):
        """
        ë¨¸ë¦¬ ì˜ì—­ì— ë¸”ëŸ¬ íš¨ê³¼ ì ìš©
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            head_boxes: ë¨¸ë¦¬ ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë¸”ëŸ¬ ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        """
        result_image = image.copy()
        
        for box in head_boxes:
            x1, y1, x2, y2 = box
            
            # ì¢Œí‘œ ë²”ìœ„ ê²€ì¦
            h, w = image.shape[:2]
            x1 = max(0, min(x1, w-1))
            y1 = max(0, min(y1, h-1))
            x2 = max(x1+1, min(x2, w))
            y2 = max(y1+1, min(y2, h))
            
            # ë¨¸ë¦¬ ì˜ì—­ ì¶”ì¶œ
            head_region = result_image[y1:y2, x1:x2]
            
            if head_region.size > 0:
                hh, ww = head_region.shape[:2]
                sw = max(1, int(ww * blur_strength))
                sh = max(1, int(hh * blur_strength))
                # ì´ˆê³ ì† ë¸”ëŸ¬ (ì¶•ì†Œ í›„ í™•ëŒ€)
                small = cv2.resize(head_region, (sw, sh), interpolation=cv2.INTER_LINEAR)
                blurred = cv2.resize(small, (ww, hh), interpolation=cv2.INTER_NEAREST)

                result_image[y1:y2, x1:x2] = blurred
        
        return result_image

    def process_frame(self, frame, index_camera, frame_interval=1, blur_strength=0.01):
        """
        n í”„ë ˆì„ë§ˆë‹¤ íƒì§€ ìˆ˜í–‰, ê·¸ ì™¸ì—ëŠ” ì´ì „ íƒì§€ ê²°ê³¼ ì‚¬ìš©
        """

        if index_camera >= len(self.frame_counts):
            extra = index_camera - len(self.frame_counts) + 1
            self.frame_counts.extend([0 for _ in range(extra)])
            self.last_head_boxes.extend([] for _ in range(extra))
        
        if self.frame_counts[index_camera] % frame_interval == 0:
            self.last_head_boxes[index_camera] = self._detect_heads(frame)
            
        self.frame_counts[index_camera] += 1

        blurred_frame = self._apply_blur_to_heads(frame, self.last_head_boxes[index_camera], blur_strength)
        return blurred_frame

def main():
    parser = argparse.ArgumentParser(description="IP ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ë¸”ëŸ¬ ì²˜ë¦¬")
    parser.add_argument(
        "-i", "--interval", type=int, default=3,
        help="ë¨¸ë¦¬ íƒì§€ë¥¼ ìˆ˜í–‰í•  í”„ë ˆì„ ê°„ê²© (ê¸°ë³¸ê°’: 3)"
    )
    parser.add_argument(
        "-s", "--save", action="store_true",
        help="ì‹¤í–‰ ì¤‘ ì „ì²´ ì˜ìƒì„ ì €ì¥ (ì›ë³¸ ë° ë¸”ëŸ¬ ì²˜ë¦¬ ì˜ìƒ)"
    )
    parser.add_argument(
        "--save-original", action="store_true",
        help="ì›ë³¸ ì˜ìƒë§Œ ì €ì¥"
    )
    parser.add_argument(
        "--save-blurred", action="store_true",
        help="ë¸”ëŸ¬ ì²˜ë¦¬ ì˜ìƒë§Œ ì €ì¥"
    )

    parser.add_argument(
        "-c", "--confidence", type=float, default=0.3,
        help="ë¨¸ë¦¬ íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.3)"
    )
    parser.add_argument(
        "-f", "--fps", type=float, default=15.0,
        help="ë¹„ë””ì˜¤ FPS (ê¸°ë³¸ê°’: 15.0)"
    )

    args = parser.parse_args()
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ì½ê¸°
    interval = args.interval
    
    model_path = 'best_re_final.engine'
    confidence_threshold = args.confidence
    rtsp_url_1 = 'rtsp://root:root@192.168.1.101:554/cam0_0'
    rtsp_url_2 = 'rtsp://root:root@192.168.1.102:554/cam0_1'
    
    # ë¹„ë””ì˜¤/ì¹´ë©”ë¼ ì„¤ì •
    video_fps = args.fps
    video_codec = 'mp4v'
    output_dir = 'output'
    num_cameras = 2
    blur_strength = 0.01

    # ì €ì¥ ì„¤ì • í™•ì¸
    save_original = args.save or args.save_original
    save_blurred = args.save or args.save_blurred
    save_enabled = save_original or save_blurred

    # output ë””ë ‰í† ë¦¬ ìƒì„± (ì €ì¥ì´ í™œì„±í™”ëœ ê²½ìš°)
    if save_enabled:
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")

    print(f"ğŸ”§ ì„¤ì •:")
    print(f"   - ëª¨ë¸ ê²½ë¡œ: {model_path}")
    print(f"   - ì‹ ë¢°ë„ ì„ê³„ê°’: {confidence_threshold}")
    print(f"   - íƒì§€ ê°„ê²©: {interval}í”„ë ˆì„")
    print(f"   - ë¸”ëŸ¬ ê°•ë„: {blur_strength}")
    print(f"   - ì¹´ë©”ë¼ ê°œìˆ˜: {num_cameras}")
    print(f"   - ë¹„ë””ì˜¤ FPS: {video_fps}")
    print(f"   - ë¹„ë””ì˜¤ ì½”ë±: {video_codec}")
    print(f"   - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print(f"   - ì¹´ë©”ë¼ 1: {rtsp_url_1}")
    print(f"   - ì¹´ë©”ë¼ 2: {rtsp_url_2}")
    print(f"   - ì €ì¥ ëª¨ë“œ: {'í™œì„±í™”' if save_enabled else 'ë¹„í™œì„±í™”'}")
    if save_enabled:
        save_types = []
        if save_original:
            save_types.append("ì›ë³¸")
        if save_blurred:
            save_types.append("ë¸”ëŸ¬")
        print(f"   - ì €ì¥ íƒ€ì…: {', '.join(save_types)}")

    cap1 = cv2.VideoCapture(rtsp_url_1)
    cap2 = cv2.VideoCapture(rtsp_url_2)
    blurrer = HeadBlurrer(model_path=model_path, num_camera=num_cameras)
    blurrer.conf_threshold = confidence_threshold

    if not cap1.isOpened() or not cap2.isOpened():
        print("ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    # ì €ì¥ ê´€ë ¨ ë³€ìˆ˜ ì´ˆê¸°í™”
    out1_original = None
    out2_original = None
    out1_blurred = None
    out2_blurred = None

    width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))
    height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))
    width2 = int(cap2.get(cv2.CAP_PROP_FRAME_WIDTH))
    height2 = int(cap2.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fourcc = cv2.VideoWriter_fourcc(*video_codec)

    # ì €ì¥ì´ í™œì„±í™”ëœ ê²½ìš° VideoWriter ì„¤ì •
    if save_enabled:
        now = datetime.now().strftime("%Y%m%d_%H%M%S")
        print(f"ğŸ“¹ ì˜ìƒ ì €ì¥ ì‹œì‘: {now}")
        
        if save_original:
            out1_original = cv2.VideoWriter(
                os.path.join(output_dir, f"cam1_original_{now}.mp4"), 
                fourcc, video_fps, (width1, height1)
            )
            out2_original = cv2.VideoWriter(
                os.path.join(output_dir, f"cam2_original_{now}.mp4"), 
                fourcc, video_fps, (width2, height2)
            )
            print(f"   - ì›ë³¸ ì˜ìƒ: cam1_original_{now}.mp4, cam2_original_{now}.mp4")
            
        if save_blurred:
            out1_blurred = cv2.VideoWriter(
                os.path.join(output_dir, f"cam1_blurred_{now}.mp4"), 
                fourcc, video_fps, (width1, height1)
            )
            out2_blurred = cv2.VideoWriter(
                os.path.join(output_dir, f"cam2_blurred_{now}.mp4"), 
                fourcc, video_fps, (width2, height2)
            )
            print(f"   - ë¸”ëŸ¬ ì˜ìƒ: cam1_blurred_{now}.mp4, cam2_blurred_{now}.mp4")

    while True:
        ret1, frame1 = cap1.read()
        ret2, frame2 = cap2.read()
        
        if not ret1 or not ret2:
            print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        blurred_1 = blurrer.process_frame(frame1, index_camera=1, frame_interval=interval, blur_strength=blur_strength)
        blurred_2 = blurrer.process_frame(frame2, index_camera=2, frame_interval=interval, blur_strength=blur_strength)
        cv2.imshow("IP Camera Stream 1", blurred_1)
        cv2.imshow("IP Camera Stream 2", blurred_2)
        
        # ì €ì¥ì´ í™œì„±í™”ëœ ê²½ìš° í”„ë ˆì„ ì €ì¥
        if save_enabled:
            if save_original and out1_original and out2_original:
                out1_original.write(frame1)
                out2_original.write(frame2)
            
            if save_blurred and out1_blurred and out2_blurred:
                out1_blurred.write(blurred_1)
                out2_blurred.write(blurred_2)
        
        key = cv2.waitKey(1) & 0xFF
        # 'q' í‚¤ë¡œ ì¢…ë£Œ
        if key == ord('q'):
            print("ğŸ”´ ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
            break

    # ë¦¬ì†ŒìŠ¤ í•´ì œ
    print("ğŸ”„ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
    cap1.release()
    cap2.release()
    
    # VideoWriter í•´ì œ ë° ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€
    if save_enabled:
        saved_files = []
        if out1_original:
            out1_original.release()
            saved_files.extend([f"cam1_original_{now}.mp4", f"cam2_original_{now}.mp4"])
        if out2_original:
            out2_original.release()
        if out1_blurred:
            out1_blurred.release()
            saved_files.extend([f"cam1_blurred_{now}.mp4", f"cam2_blurred_{now}.mp4"])
        if out2_blurred:
            out2_blurred.release()
        
        print(f"âœ… ì˜ìƒ ì €ì¥ ì™„ë£Œ:")
        for file in saved_files:
            print(f"   - {os.path.join(output_dir, file)}")
    
    cv2.destroyAllWindows()
    print("ğŸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

if __name__ == "__main__":
    main()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# rtsp_simulator_ffmpeg.pyê°€ ë™ì  ë¡œë”©í•˜ëŠ” apply_blur ë˜í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_blurrer_cache = {"obj": None}   
       # ì‹±ê¸€í„´ ìºì‹œ
import threading
_blurrer = HeadBlurrer(model_path="best_re_final.engine", num_camera=16)
_thread2cam = {}  

def apply_blur(frame,
               index_camera: int = 1,
               frame_interval: int = 3,
               blur_strength: float = 0.01):

    tid = threading.get_ident()
    idx = _thread2cam.setdefault(tid, len(_thread2cam) + 1)  # 1â€‘base
    return _blurrer.process_frame(
        frame, index_camera=idx,
        frame_interval=frame_interval,
        blur_strength=blur_strength
    )