import cv2
import time
from datetime import datetime
import os
import argparse
import numpy as np
import csv
import json
from dotenv import load_dotenv

# ultralytics ì„ íƒì  ì„í¬íŠ¸
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("âš ï¸ ultralyticsê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - ê¸°ë³¸ ë¸”ëŸ¬ ëª¨ë“œë¡œ ë™ì‘")

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

def get_model_path():
    """í™˜ê²½ë³€ìˆ˜ì—ì„œ HEAD_BLUR_MODEL_PATHë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    env_model_path = os.getenv('HEAD_BLUR_MODEL_PATH')
    if env_model_path:
        # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        if not os.path.isabs(env_model_path):
            # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(current_dir)  # blur_moduleì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬
            model_path = os.path.join(project_root, env_model_path)
        else:
            model_path = env_model_path
        
        print(f"âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ ê²½ë¡œ ë¡œë“œ: {model_path}")
        return model_path
    else:
        # ê¸°ë³¸ ê²½ë¡œ (fallback)
        current_dir = os.path.dirname(os.path.abspath(__file__))
        default_model_path = os.path.join(current_dir, "models", "best_re_final.pt")
        print(f"âš ï¸ í™˜ê²½ë³€ìˆ˜ HEAD_BLUR_MODEL_PATHê°€ ì—†ìŒ. ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©: {default_model_path}")
        return default_model_path

class HeadBlurrer:
    def __init__(self, model_path=None, conf_threshold=0.3, enable_face_counting=False):
        """
        HeadBlurrer ì´ˆê¸°í™”
        
        Args:
            model_path (str): PyTorch ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (Noneì¸ ê²½ìš° í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
            conf_threshold (float): íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
            enable_face_counting (bool): ì–¼êµ´ íƒì§€ ìˆ˜ ê¸°ë¡ ê¸°ëŠ¥ í™œì„±í™”
        """
        # model_pathê°€ Noneì¸ ê²½ìš° í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        if model_path is None:
            self.model_path = get_model_path()
        else:
            self.model_path = model_path
        self.conf_threshold = conf_threshold  # íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
        self.enable_face_counting = enable_face_counting
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model()
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        
        # ë‹¨ì¼ ì¹´ë©”ë¼ìš© ë³€ìˆ˜ë“¤
        self.frame_count = 0
        self.last_head_boxes = []
        
        # ì–¼êµ´ íƒì§€ ê¸°ë¡ìš© (í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥)
        if self.enable_face_counting:
            self.detection_records = []  # ê° í”„ë ˆì„ì˜ íƒì§€ ì •ë³´ ì €ì¥
            self.stats = {}  # ì¹´ë©”ë¼ë³„ í†µê³„
            print("ğŸ” ì–¼êµ´ íƒì§€ ìˆ˜ ê¸°ë¡ ê¸°ëŠ¥ í™œì„±í™”")
    
    def _load_model(self):
        """PyTorch YOLO ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        try:
            model = YOLO(self.model_path)
            return model
        except Exception as e:
            raise RuntimeError(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
    def _detect_heads(self, image):
        """
        ë¨¸ë¦¬ íƒì§€ ìˆ˜í–‰
        

        Args:
            image: OpenCV ì´ë¯¸ì§€ (BGR)
        
        Returns:
            list: ë¨¸ë¦¬ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ [[x1,y1,x2,y2], ...]
        """
        try:
            # YOLO ì¶”ë¡  
            results = self.model(image, conf=self.conf_threshold, verbose=False)
            
            head_boxes = []
            if results[0].boxes is not None:
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ
                boxes = results[0].boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2] í˜•íƒœ
                for box in boxes:
                    x1, y1, x2, y2 = box.astype(int)
                    head_boxes.append([x1, y1, x2, y2])
            else:
                print("íƒì§€ëœ ë¨¸ë¦¬ ì—†ìŒ")
            
            return head_boxes
            
        except Exception as e:
            print(f"âš ï¸  ë¨¸ë¦¬ íƒì§€ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def _record_detection(self, frame_number, face_count, detection_performed=False):
        """
        ì–¼êµ´ íƒì§€ ì •ë³´ ê¸°ë¡ (í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥)
        
        Args:
            frame_number: í”„ë ˆì„ ë²ˆí˜¸
            face_count: íƒì§€ëœ ì–¼êµ´ ìˆ˜
            detection_performed: ì‹¤ì œ íƒì§€ë¥¼ ìˆ˜í–‰í–ˆëŠ”ì§€ ì—¬ë¶€ (ê°„ê²© íƒì§€ìš©)
        """
        if not self.enable_face_counting:
            return
            
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
        
        record = {
            'timestamp': timestamp,
            'frame_number': frame_number,
            'face_count': face_count,
            'detection_performed': detection_performed,
            'confidence_threshold': self.conf_threshold
        }
        
        self.detection_records.append(record)
        
        # í†µê³„ ì—…ë°ì´íŠ¸ (ë‹¨ì¼ ì¹´ë©”ë¼ìš©)
        if not hasattr(self, 'stats'):
            self.stats = {
                'total_frames': 0,
                'total_faces': 0,
                'detection_frames': 0,
                'max_faces': 0,
                'avg_faces': 0.0
            }
        
        self.stats['total_frames'] += 1
        self.stats['total_faces'] += face_count
        if detection_performed:
            self.stats['detection_frames'] += 1
        self.stats['max_faces'] = max(self.stats['max_faces'], face_count)
        self.stats['avg_faces'] = self.stats['total_faces'] / self.stats['total_frames']

    def save_detection_records(self, output_dir="output", filename_prefix="face_detection"):
        """
        ì–¼êµ´ íƒì§€ ê¸°ë¡ì„ íŒŒì¼ë¡œ ì €ì¥ (í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥)
        
        Args:
            output_dir: ì €ì¥ ë””ë ‰í† ë¦¬
            filename_prefix: íŒŒì¼ëª… ì ‘ë‘ì‚¬
        """
        if not self.enable_face_counting or not self.detection_records:
            print("âš ï¸ ì €ì¥í•  ì–¼êµ´ íƒì§€ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # CSV íŒŒì¼ë¡œ ìƒì„¸ ê¸°ë¡ ì €ì¥
        csv_filename = f"{filename_prefix}_details_{timestamp}.csv"
        csv_path = os.path.join(output_dir, csv_filename)
        
        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['timestamp', 'frame_number', 'face_count', 'detection_performed', 'confidence_threshold']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(self.detection_records)
            
        # JSON íŒŒì¼ë¡œ í†µê³„ ì €ì¥
        json_filename = f"{filename_prefix}_stats_{timestamp}.json"
        json_path = os.path.join(output_dir, json_filename)
        
        summary_data = {
            'generation_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'total_records': len(self.detection_records),
            'camera_statistics': self.stats,
            'overall_stats': {
                'total_frames_all_cameras': self.stats['total_frames'],
                'total_faces_all_cameras': self.stats['total_faces'],
                'cameras_count': 1 # ë‹¨ì¼ ì¹´ë©”ë¼
            }
        }
        
        with open(json_path, 'w', encoding='utf-8') as jsonfile:
            json.dump(summary_data, jsonfile, indent=2, ensure_ascii=False)
            
        print(f"ğŸ“Š ì–¼êµ´ íƒì§€ ê¸°ë¡ ì €ì¥ ì™„ë£Œ:")
        print(f"   - ìƒì„¸ ê¸°ë¡: {csv_path} ({len(self.detection_records)}ê°œ ë ˆì½”ë“œ)")
        print(f"   - í†µê³„ ìš”ì•½: {json_path}")
        
        # ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
        print(f"   - ì¹´ë©”ë¼ í†µê³„: {self.stats['total_frames']}í”„ë ˆì„, í‰ê·  {self.stats['avg_faces']:.1f}ëª…, ìµœëŒ€ {self.stats['max_faces']}ëª…")
    
    def _apply_blur_to_heads(self, image, head_boxes, blur_strength=0.01):
        """
        ë¨¸ë¦¬ ì˜ì—­ì— ë¸”ëŸ¬ íš¨ê³¼ ì ìš© (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”)
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            head_boxes: ë¨¸ë¦¬ ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸
            blur_strength: ë¸”ëŸ¬ ê°•ë„ (0.15 = 15% í¬ê¸°ë¡œ ì¶•ì†Œ)
        
        Returns:
            ë¸”ëŸ¬ ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        """
        if not head_boxes:
            return image
            
        result_image = image.copy()
        h, w = image.shape[:2]
        
        # ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•´ í•œë²ˆë§Œ ë¸”ëŸ¬ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        blur_h = max(1, int(h * blur_strength))
        blur_w = max(1, int(w * blur_strength))
        
        # í•œë²ˆì˜ resize ì—°ì‚°ìœ¼ë¡œ ì „ì²´ ì´ë¯¸ì§€ ë¸”ëŸ¬ ìƒì„±
        small_image = cv2.resize(image, (blur_w, blur_h), interpolation=cv2.INTER_LINEAR)
        blurred_full = cv2.resize(small_image, (w, h), interpolation=cv2.INTER_NEAREST)
        
        # ëª¨ë“  head box ì˜ì—­ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        for box in head_boxes:
            x1, y1, x2, y2 = box
            
            # ì¢Œí‘œ ë²”ìœ„ ê²€ì¦ ë° ì •ê·œí™”
            x1 = max(0, min(x1, w-1))
            y1 = max(0, min(y1, h-1))
            x2 = max(x1+1, min(x2, w))
            y2 = max(y1+1, min(y2, h))
            
            # ë¸”ëŸ¬ëœ ì˜ì—­ì„ ê²°ê³¼ ì´ë¯¸ì§€ì— ë³µì‚¬ (vectorized operation)
            if (x2 - x1) > 0 and (y2 - y1) > 0:
                result_image[y1:y2, x1:x2] = blurred_full[y1:y2, x1:x2]
        
        return result_image

    def process_frame(self, frame, frame_interval=1, blur_strength=0.01, should_detect=None):
        """
        n í”„ë ˆì„ë§ˆë‹¤ íƒì§€ ìˆ˜í–‰, ê·¸ ì™¸ì—ëŠ” ì´ì „ íƒì§€ ê²°ê³¼ ì‚¬ìš©
        
        Args:
            frame: ì…ë ¥ í”„ë ˆì„
            frame_interval: íƒì§€ ê°„ê²© (should_detectê°€ Noneì¼ ë•Œë§Œ ì‚¬ìš©)
            blur_strength: ë¸”ëŸ¬ ê°•ë„
            should_detect: ì™¸ë¶€ì—ì„œ íƒì§€ ì—¬ë¶€ ê²°ì • (Noneì´ë©´ ë‚´ë¶€ ê°„ê²© ì œì–´ ì‚¬ìš©)
        """
        detection_performed = False
        
        # ì™¸ë¶€ì—ì„œ íƒì§€ ì—¬ë¶€ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•œ ê²½ìš° ìš°ì„  ì‚¬ìš©
        if should_detect is not None:
            if should_detect:
                self.last_head_boxes = self._detect_heads(frame)
                detection_performed = True
        else:
            # ê¸°ì¡´ ë°©ì‹: ë‚´ë¶€ ê°„ê²© ì œì–´
            if self.frame_count % frame_interval == 0:
                self.last_head_boxes = self._detect_heads(frame)
                detection_performed = True
            
        # ì–¼êµ´ íƒì§€ ê¸°ë¡ (í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥)
        face_count = len(self.last_head_boxes)
        self._record_detection(
            frame_number=self.frame_count,
            face_count=face_count,
            detection_performed=detection_performed
        )
            
        self.frame_count += 1

        blurred_frame = self._apply_blur_to_heads(frame, self.last_head_boxes, blur_strength)
        return blurred_frame

def main():
    parser = argparse.ArgumentParser(description="IP ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ë¸”ëŸ¬ ì²˜ë¦¬")
    parser.add_argument(
        "-i", "--interval", type=int, default=3,
        help="ë¨¸ë¦¬ íƒì§€ë¥¼ ìˆ˜í–‰í•  í”„ë ˆì„ ê°„ê²© (ê¸°ë³¸ê°’: 3)"
    )
    parser.add_argument(
        "-s", "--save", action="store_true",
        help="ì‹¤í–‰ ì¤‘ ì „ì²´ ì˜ìƒì„ ì €ì¥ (ì›ë³¸ ë° ë¸”ëŸ¬ ì²˜ë¦¬ ì˜ìƒ)"
    )
    parser.add_argument(
        "--save-original", action="store_true",
        help="ì›ë³¸ ì˜ìƒë§Œ ì €ì¥"
    )
    parser.add_argument(
        "--save-blurred", action="store_true",
        help="ë¸”ëŸ¬ ì²˜ë¦¬ ì˜ìƒë§Œ ì €ì¥"
    )

    parser.add_argument(
        "-c", "--confidence", type=float, default=0.2,
        help="ë¨¸ë¦¬ íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.3)"
    )
    parser.add_argument(
        "-f", "--fps", type=float, default=15.0,
        help="ë¹„ë””ì˜¤ FPS (ê¸°ë³¸ê°’: 15.0)"
    )
    parser.add_argument(
        "-b", "--blur-strength", type=float, default=0.01,
        help="ë¸”ëŸ¬ ê°•ë„ (ê¸°ë³¸ê°’: 0.01, ë²”ìœ„: 0.01-1.0)"
    )
    
    # ì–¼êµ´ íƒì§€ ê¸°ë¡ ê¸°ëŠ¥ (í…ŒìŠ¤íŠ¸ìš©)
    parser.add_argument(
        "--enable-face-counting", action="store_true",
        help="ì–¼êµ´ íƒì§€ ìˆ˜ ê¸°ë¡ ê¸°ëŠ¥ í™œì„±í™” (í…ŒìŠ¤íŠ¸ìš©)"
    )
    parser.add_argument(
        "--face-count-output", type=str, default="output",
        help="ì–¼êµ´ íƒì§€ ê¸°ë¡ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: output)"
    )

    args = parser.parse_args()
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ì½ê¸°
    interval = args.interval
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    model_path = get_model_path()
    confidence_threshold = args.confidence
    rtsp_url = 'rtsp://root:root@192.168.1.101:554/cam0_0'  # ë‹¨ì¼ ì¹´ë©”ë¼
    
    # ë¹„ë””ì˜¤/ì¹´ë©”ë¼ ì„¤ì •
    video_fps = args.fps
    video_codec = 'mp4v'
    output_dir = 'output'
    blur_strength = args.blur_strength
    enable_face_counting = args.enable_face_counting
    face_count_output_dir = args.face_count_output

    # ì €ì¥ ì„¤ì • í™•ì¸
    save_original = args.save or args.save_original
    save_blurred = args.save or args.save_blurred
    save_enabled = save_original or save_blurred

    # output ë””ë ‰í† ë¦¬ ìƒì„± (ì €ì¥ì´ í™œì„±í™”ëœ ê²½ìš°)
    if save_enabled:
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")

    print(f"ğŸ”§ ì„¤ì •:")
    print(f"   - ëª¨ë¸ ê²½ë¡œ: {model_path}")
    print(f"   - ì‹ ë¢°ë„ ì„ê³„ê°’: {confidence_threshold}")
    print(f"   - íƒì§€ ê°„ê²©: {interval}í”„ë ˆì„")
    print(f"   - ë¸”ëŸ¬ ê°•ë„: {blur_strength}")
    print(f"   - ì–¼êµ´ íƒì§€ ê¸°ë¡: {'í™œì„±í™”' if enable_face_counting else 'ë¹„í™œì„±í™”'}")
    if enable_face_counting:
        print(f"   - ê¸°ë¡ ì €ì¥ ê²½ë¡œ: {face_count_output_dir}")
    print(f"   - ë¹„ë””ì˜¤ FPS: {video_fps}")
    print(f"   - ë¹„ë””ì˜¤ ì½”ë±: {video_codec}")
    print(f"   - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print(f"   - ì¹´ë©”ë¼: {rtsp_url}")
    print(f"   - ì €ì¥ ëª¨ë“œ: {'í™œì„±í™”' if save_enabled else 'ë¹„í™œì„±í™”'}")
    if save_enabled:
        save_types = []
        if save_original:
            save_types.append("ì›ë³¸")
        if save_blurred:
            save_types.append("ë¸”ëŸ¬")
        print(f"   - ì €ì¥ íƒ€ì…: {', '.join(save_types)}")

    cap = cv2.VideoCapture(rtsp_url)
    blurrer = HeadBlurrer(
        conf_threshold=confidence_threshold,
        enable_face_counting=enable_face_counting
    )

    if not cap.isOpened():
        print("ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    # ì €ì¥ ê´€ë ¨ ë³€ìˆ˜ ì´ˆê¸°í™”
    out_original = None
    out_blurred = None

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fourcc = cv2.VideoWriter.fourcc(*video_codec)

    # ì €ì¥ì´ í™œì„±í™”ëœ ê²½ìš° VideoWriter ì„¤ì •
    if save_enabled:
        now = datetime.now().strftime("%Y%m%d_%H%M%S")
        print(f"ğŸ“¹ ì˜ìƒ ì €ì¥ ì‹œì‘: {now}")
        
        if save_original:
            out_original = cv2.VideoWriter(
                os.path.join(output_dir, f"cam_original_{now}.mp4"), 
                fourcc, video_fps, (width, height)
            )
            print(f"   - ì›ë³¸ ì˜ìƒ: cam_original_{now}.mp4")
            
        if save_blurred:
            out_blurred = cv2.VideoWriter(
                os.path.join(output_dir, f"cam_blurred_{now}.mp4"), 
                fourcc, video_fps, (width, height)
            )
            print(f"   - ë¸”ëŸ¬ ì˜ìƒ: cam_blurred_{now}.mp4")

    try:
        while True:
            ret, frame = cap.read()
            
            if not ret:
                print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break

            blurred_frame = blurrer.process_frame(frame, frame_interval=interval, blur_strength=blur_strength)
            cv2.imshow("IP Camera Stream", blurred_frame)
            
            # ì €ì¥ì´ í™œì„±í™”ëœ ê²½ìš° í”„ë ˆì„ ì €ì¥
            if save_enabled:
                if save_original and out_original:
                    out_original.write(frame)
                
                if save_blurred and out_blurred:
                    out_blurred.write(blurred_frame)
            
            key = cv2.waitKey(1) & 0xFF
            # 'q' í‚¤ë¡œ ì¢…ë£Œ
            if key == ord('q'):
                print("ğŸ”´ ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
                break
                
    except KeyboardInterrupt:
        print("ğŸ”´ ì‚¬ìš©ì ì¤‘ë‹¨ (Ctrl+C)")
    except Exception as e:
        print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        # ì–¼êµ´ íƒì§€ ê¸°ë¡ ì €ì¥ (í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥)
        if enable_face_counting:
            print("ğŸ’¾ ì–¼êµ´ íƒì§€ ê¸°ë¡ ì €ì¥ ì¤‘...")
            blurrer.save_detection_records(output_dir=face_count_output_dir)

        # ë¦¬ì†ŒìŠ¤ í•´ì œ
        print("ğŸ”„ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        cap.release()
        
        # VideoWriter í•´ì œ ë° ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€
        if save_enabled:
            saved_files = []
            if out_original:
                out_original.release()
                saved_files.append(f"cam_original_{now}.mp4")
            if out_blurred:
                out_blurred.release()
                saved_files.append(f"cam_blurred_{now}.mp4")
            
            print(f"âœ… ì˜ìƒ ì €ì¥ ì™„ë£Œ:")
            for file in saved_files:
                print(f"   - {os.path.join(output_dir, file)}")
        
        cv2.destroyAllWindows()
        print("ğŸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

if __name__ == "__main__":
    main()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# rtsp_simulator_ffmpeg.pyê°€ ë™ì  ë¡œë”©í•˜ëŠ” apply_blur ë˜í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_blurrer = HeadBlurrer(
    conf_threshold=0.3,
    enable_face_counting=False  # ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”
)

def apply_blur(frame,
               frame_interval: int = 3,
               blur_strength: float = 0.01,
               should_detect=None):
    """
    ë‹¨ì¼ ì¹´ë©”ë¼ìš© ë¸”ëŸ¬ ì ìš© í•¨ìˆ˜
    
    Args:
        frame: ì…ë ¥ í”„ë ˆì„
        frame_interval: íƒì§€ ê°„ê²© (should_detectê°€ Noneì¼ ë•Œë§Œ ì‚¬ìš©)
        blur_strength: ë¸”ëŸ¬ ê°•ë„
        should_detect: ì™¸ë¶€ì—ì„œ íƒì§€ ì—¬ë¶€ ê²°ì • (Noneì´ë©´ ë‚´ë¶€ ê°„ê²© ì œì–´ ì‚¬ìš©)
    
    Returns:
        ë¸”ëŸ¬ ì²˜ë¦¬ëœ í”„ë ˆì„
    """
    return _blurrer.process_frame(
        frame, 
        frame_interval=frame_interval,
        blur_strength=blur_strength,
        should_detect=should_detect
    )

def enable_face_counting_for_blurrer(enable=True, output_dir="output"):
    """
    ë‹¨ì¼ ì¹´ë©”ë¼ìš© ì–¼êµ´ íƒì§€ ê¸°ë¡ ê¸°ëŠ¥ í™œì„±í™”/ë¹„í™œì„±í™” (í…ŒìŠ¤íŠ¸ìš©)
    
    Args:
        enable (bool): ê¸°ëŠ¥ í™œì„±í™” ì—¬ë¶€
        output_dir (str): ê¸°ë¡ ì €ì¥ ë””ë ‰í† ë¦¬
    """
    global _blurrer
    _blurrer.enable_face_counting = enable
    if enable:
        _blurrer.detection_records = []
        _blurrer.stats = {} # ë‹¨ì¼ ì¹´ë©”ë¼ìš© í†µê³„ ì´ˆê¸°í™”
        print("ğŸ” ë‹¨ì¼ ì¹´ë©”ë¼ìš© ì–¼êµ´ íƒì§€ ê¸°ë¡ ê¸°ëŠ¥ í™œì„±í™”")
    return output_dir

def save_face_counting_records(output_dir="output", filename_prefix="face_detection_wrapper"):
    """
    ë‹¨ì¼ ì¹´ë©”ë¼ìš© ì–¼êµ´ íƒì§€ ê¸°ë¡ ì €ì¥ (í…ŒìŠ¤íŠ¸ìš©)
    
    Args:
        output_dir (str): ì €ì¥ ë””ë ‰í† ë¦¬
        filename_prefix (str): íŒŒì¼ëª… ì ‘ë‘ì‚¬
    """
    global _blurrer
    if _blurrer and _blurrer.enable_face_counting:
        _blurrer.save_detection_records(output_dir=output_dir, filename_prefix=filename_prefix)
        return True
    else:
        print("âš ï¸ ì–¼êµ´ íƒì§€ ê¸°ë¡ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return False
