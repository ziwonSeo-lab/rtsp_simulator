"""
ê³µìœ  ì›Œì»¤ ì•„í‚¤í…ì²˜ - RTSP ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ê³µìœ  ì›Œì»¤ ë°©ì‹ìœ¼ë¡œ ì„¤ê³„ë˜ì–´:
- ìº¡ì²˜ ì›Œì»¤: ì„¤ì • ê°œìˆ˜ë§Œí¼ ìƒì„±, ëª¨ë“  ìŠ¤íŠ¸ë¦¼ì„ ìˆœí™˜ ì²˜ë¦¬
- ë¸”ëŸ¬ ì›Œì»¤: ì„¤ì • ê°œìˆ˜ë§Œí¼ ìƒì„±, ëª¨ë“  ìŠ¤íŠ¸ë¦¼ íë¥¼ ìˆœí™˜ ì²˜ë¦¬  
- ì €ì¥ ì›Œì»¤: ì„¤ì • ê°œìˆ˜ë§Œí¼ ìƒì„±, ëª¨ë“  ìŠ¤íŠ¸ë¦¼ íë¥¼ ìˆœí™˜ ì²˜ë¦¬
"""

import cv2
import time
import queue
import logging
import os
import random
import importlib.util
import subprocess
import numpy as np
from datetime import datetime
from typing import Optional, Dict, List
from dataclasses import dataclass


def rtsp_capture_process(worker_id, sources, blur_queues, preview_queue, stats_dict, stop_event, config):
    """ê³µìœ  ìº¡ì²˜ ì›Œì»¤ - ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ì„ ìˆœí™˜ ì²˜ë¦¬"""
    logger = logging.getLogger(f"CAPTURE_{worker_id}")
    current_pid = os.getpid()
    logger.info(f"ğŸ“¹ ìº¡ì²˜ ì›Œì»¤ ì‹¤í–‰ ì¤‘ - PID: {current_pid}, Worker: {worker_id}")
    logger.info(f"   ğŸ†” í”„ë¡œì„¸ìŠ¤ ID: {current_pid}")
    logger.info(f"   ğŸ”§ ì›Œì»¤ ID: {worker_id}")
    logger.info(f"   ğŸ¯ ë‹¤ì¤‘ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ - {len(sources)}ê°œ ì†ŒìŠ¤, {len(blur_queues)}ê°œ ë¸”ëŸ¬í")
    
    # ë¸”ëŸ¬ ëª¨ë“ˆ ë¡œë“œ (ì›Œì»¤ë³„ë¡œ ë…ë¦½ì )
    blur_module = None
    if config.blur_module_path:
        try:
            logger.info(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ ë¡œë“œ ì‹œë„ - ê²½ë¡œ: {config.blur_module_path}")
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(config.blur_module_path):
                logger.error(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ - {config.blur_module_path}")
                blur_module = None
            else:
                logger.info(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ íŒŒì¼ ì¡´ì¬ í™•ì¸ë¨")
                
                spec = importlib.util.spec_from_file_location(f"blur_module_{worker_id}", config.blur_module_path)
                if spec is None:
                    logger.error(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ spec ìƒì„± ì‹¤íŒ¨")
                    blur_module = None
                else:
                    logger.info(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ spec ìƒì„± ì„±ê³µ")
                    blur_module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(blur_module)
                    logger.info(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ ì‹¤í–‰ ì™„ë£Œ")
                    
                    if hasattr(blur_module, 'HeadBlurrer'):
                        logger.info(f"Worker {worker_id}: HeadBlurrer í´ë˜ìŠ¤ ë°œê²¬")
                        try:
                            head_blurrer = blur_module.HeadBlurrer()
                            blur_module.apply_blur = lambda frame: head_blurrer.process_frame(frame)
                            logger.info(f"Worker {worker_id}: HeadBlurrer ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° apply_blur í•¨ìˆ˜ ì„¤ì • ì™„ë£Œ")
                        except Exception as init_error:
                            logger.error(f"Worker {worker_id}: HeadBlurrer ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ - {init_error}")
                            logger.info(f"Worker {worker_id}: ê¸°ë³¸ ë¸”ëŸ¬ ì²˜ë¦¬ë¡œ ëŒ€ì²´")
                            blur_module = None
                    else:
                        logger.warning(f"Worker {worker_id}: HeadBlurrer í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        # ì‚¬ìš© ê°€ëŠ¥í•œ ì†ì„±ë“¤ ì¶œë ¥
                        available_attrs = [attr for attr in dir(blur_module) if not attr.startswith('_')]
                        logger.info(f"Worker {worker_id}: ì‚¬ìš© ê°€ëŠ¥í•œ ì†ì„±ë“¤: {available_attrs}")
            
            logger.info(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            logger.error(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨ - {e}")
            import traceback
            logger.error(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨ ìƒì„¸ - {traceback.format_exc()}")
            blur_module = None
    
    # ì›Œì»¤ë³„ ë‹´ë‹¹ ìŠ¤íŠ¸ë¦¼ ê³„ì‚° (ë¼ìš´ë“œ ë¡œë¹ˆ ë¶„í• )
    worker_index = int(worker_id.split('_')[1]) - 1  # capture_1 -> 0, capture_2 -> 1
    total_workers = config.capture_workers
    
    # ì´ ì›Œì»¤ê°€ ë‹´ë‹¹í•  ìŠ¤íŠ¸ë¦¼ ì¸ë±ìŠ¤ë“¤ ê³„ì‚°
    assigned_stream_indices = []
    for i in range(len(sources)):
        if i % total_workers == worker_index:
            assigned_stream_indices.append(i)
    
    logger.info(f"Worker {worker_id}: ë‹´ë‹¹ ìŠ¤íŠ¸ë¦¼ ì¸ë±ìŠ¤ - {assigned_stream_indices}")
    
    # ê° ìŠ¤íŠ¸ë¦¼ë³„ OpenCV VideoCapture ì´ˆê¸°í™” (ë‹´ë‹¹ ìŠ¤íŠ¸ë¦¼ë§Œ)
    caps = {}
    # ì´ ì›Œì»¤ê°€ ë‹´ë‹¹í•˜ëŠ” ìŠ¤íŠ¸ë¦¼ IDë“¤ë§Œ ìƒì„±
    assigned_stream_ids = [f"stream_{i+1}" for i in assigned_stream_indices]
    
    for i in assigned_stream_indices:
        source = sources[i]
        stream_id = f"stream_{i+1}"
        cap = cv2.VideoCapture(source)
        
        # ì•ˆì „í•œ ì†ì„± ì„¤ì •
        try:
            if hasattr(cv2, 'CAP_PROP_BUFFER_SIZE'):
                cap.set(cv2.CAP_PROP_BUFFER_SIZE, 1)
        except Exception as e:
            logger.debug(f"CAP_PROP_BUFFER_SIZE ì„¤ì • ì‹¤íŒ¨: {e}")
        
        if config.force_fps:
            try:
                if hasattr(cv2, 'CAP_PROP_FPS'):
                    cap.set(cv2.CAP_PROP_FPS, config.input_fps)
            except Exception as e:
                logger.debug(f"CAP_PROP_FPS ì„¤ì • ì‹¤íŒ¨: {e}")
        
        # ì—°ê²° ì„¤ì •
        if source.startswith('rtsp://') or source.startswith('http://'):
            try:
                if hasattr(cv2, 'CAP_PROP_OPEN_TIMEOUT_MSEC'):
                    cap.set(cv2.CAP_PROP_OPEN_TIMEOUT_MSEC, config.connection_timeout * 1000)
                if hasattr(cv2, 'CAP_PROP_READ_TIMEOUT_MSEC'):
                    cap.set(cv2.CAP_PROP_READ_TIMEOUT_MSEC, 5000)
            except Exception as e:
                logger.debug(f"ì—°ê²° ì„¤ì • ì‹¤íŒ¨: {e}")
        
        if not cap.isOpened():
            logger.error(f"ì†ŒìŠ¤ ì—°ê²° ì‹¤íŒ¨: {source}")
            continue
            
        # ì²« ë²ˆì§¸ í”„ë ˆì„ ì½ê¸° ì‹œë„
        ret, frame = cap.read()
        if not ret:
            cap.release()
            logger.error(f"ì†ŒìŠ¤ì—ì„œ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨: {source}")
            continue
        
        caps[stream_id] = cap
        logger.info(f"Worker {worker_id}: Stream {stream_id} ì†ŒìŠ¤ ì—°ê²° ì„±ê³µ - {source}")
    
    # ìŠ¤íŠ¸ë¦¼ë³„ í”„ë ˆì„ ì¹´ìš´í„° ë° ìƒíƒœ (ë‹´ë‹¹ ìŠ¤íŠ¸ë¦¼ë§Œ)
    frame_counts = {stream_id: 0 for stream_id in assigned_stream_ids}
    failed_counts = {stream_id: 0 for stream_id in assigned_stream_ids}
    start_time = time.time()
    
    # FPS ì œì–´ë¥¼ ìœ„í•œ í”„ë ˆì„ ê°„ê²© ê³„ì‚°
    frame_interval = 1.0 / config.input_fps
    
    # ìŠ¤íŠ¸ë¦¼ ìˆœí™˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì¸ë±ìŠ¤
    stream_index = 0
    
    try:
        while not stop_event.is_set():
            # ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„ ì²´í¬
            if config.max_duration_seconds:
                elapsed_time = time.time() - start_time
                if elapsed_time >= config.max_duration_seconds:
                    break
            
            # ì²˜ë¦¬í•  ìŠ¤íŠ¸ë¦¼ì´ ì—†ìœ¼ë©´ ì ê¹ ëŒ€ê¸°
            if not caps:
                time.sleep(0.1)
                continue
            
            # ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¼ ì„ íƒ
            stream_keys = list(caps.keys())
            if not stream_keys:
                time.sleep(0.1)
                continue
                
            current_stream_id = stream_keys[stream_index % len(stream_keys)]
            stream_index += 1
            
            cap = caps[current_stream_id]
            
            # FPS ì œì–´
            next_frame_time = start_time + (frame_counts[current_stream_id] + 1) * frame_interval
            sleep_time = next_frame_time - time.time()
            if sleep_time > 0:
                time.sleep(min(sleep_time, 0.1))  # ìµœëŒ€ 100msë§Œ ëŒ€ê¸°
            
            ret, frame = cap.read()
            
            if not ret:
                failed_counts[current_stream_id] += 1
                if failed_counts[current_stream_id] > 10:
                    logger.error(f"Worker {worker_id}: Stream {current_stream_id} ì—°ì† ì‹¤íŒ¨ - ì¬ì—°ê²° ì‹œë„")
                    cap.release()
                    time.sleep(config.reconnect_interval)
                    
                    # ì¬ì—°ê²° ì‹œë„ (ìŠ¤íŠ¸ë¦¼ IDì—ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ)
                    stream_index_in_source = int(current_stream_id.split('_')[1]) - 1
                    source = sources[stream_index_in_source]
                    new_cap = cv2.VideoCapture(source)
                    
                    # ì¬ì—°ê²° ì‹œì—ë„ ì•ˆì „í•œ ì†ì„± ì„¤ì •
                    try:
                        if hasattr(cv2, 'CAP_PROP_BUFFER_SIZE'):
                            new_cap.set(cv2.CAP_PROP_BUFFER_SIZE, 1)
                    except:
                        pass
                    
                    if new_cap.isOpened():
                        caps[current_stream_id] = new_cap
                        failed_counts[current_stream_id] = 0
                        logger.info(f"Worker {worker_id}: Stream {current_stream_id} ì¬ì—°ê²° ì„±ê³µ")
                    else:
                        logger.error(f"Worker {worker_id}: Stream {current_stream_id} ì¬ì—°ê²° ì‹¤íŒ¨")
                        del caps[current_stream_id]
                continue
            
            failed_counts[current_stream_id] = 0
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            stats_dict[f'{current_stream_id}_received'] = stats_dict.get(f'{current_stream_id}_received', 0) + 1
            
            # í”„ë ˆì„ ì†ì‹¤ ì‹œë®¬ë ˆì´ì…˜
            if random.random() < config.frame_loss_rate:
                stats_dict[f'{current_stream_id}_lost'] = stats_dict.get(f'{current_stream_id}_lost', 0) + 1
                logger.debug(f"Worker {worker_id}: Stream {current_stream_id} í”„ë ˆì„ {frame_counts[current_stream_id]} ì‹œë®¬ë ˆì´ì…˜ ì†ì‹¤")
                continue
            
            # ë¸”ëŸ¬ íƒì§€ ê°„ê²© í™•ì¸ (íƒì§€ë¥¼ ìˆ˜í–‰í• ì§€ ê²°ì •)
            should_detect = (frame_counts[current_stream_id] % config.blur_interval == 0)
            
            # ë¸”ëŸ¬ ì²˜ë¦¬ ì‘ì—… ë°ì´í„° ì¤€ë¹„ (ëª¨ë“  í”„ë ˆì„ì„ ë¸”ëŸ¬ íì— ì „ì†¡)
            work_item = {
                'stream_id': current_stream_id,
                'thread_id': int(current_stream_id.split('_')[1]) - 1,
                'frame': frame.copy(),
                'timestamp': datetime.now(),
                'frame_number': frame_counts[current_stream_id],
                'blur_module_path': config.blur_module_path,
                'blur_interval': config.blur_interval,
                'should_detect': should_detect,  # íƒì§€ ìˆ˜í–‰ ì—¬ë¶€ (ì§€ì†ì„±ì„ ìœ„í•´ ëª¨ë“  í”„ë ˆì„ ì „ì†¡)
                'overlay_enabled': config.overlay_enabled,
                'save_enabled': config.save_enabled,
                'save_path': config.save_path,
                'save_format': config.save_format,
                'save_interval': config.save_interval,
                'save_interval_seconds': config.save_interval_seconds,
                'preview_enabled': config.preview_enabled
            }
            
            # í•´ë‹¹ ìŠ¤íŠ¸ë¦¼ì˜ ë¸”ëŸ¬ íì— ì „ì†¡
            if current_stream_id in blur_queues:
                try:
                    blur_queues[current_stream_id].put_nowait(work_item)
                except queue.Full:
                    try:
                        blur_queues[current_stream_id].get_nowait()
                        blur_queues[current_stream_id].put_nowait(work_item)
                        logger.warning(f"Worker {worker_id}: Stream {current_stream_id} ë¸”ëŸ¬í ì˜¤ë²„í”Œë¡œìš°")
                    except:
                        pass
                    time.sleep(0.01)
            
            frame_counts[current_stream_id] += 1
            
            # ì£¼ê¸°ì  ë¡œê¹…
            total_frames = sum(frame_counts.values())
            if total_frames % 100 == 0:
                active_streams = len(caps)
                logger.info(f"Worker {worker_id}: ì´ {total_frames}í”„ë ˆì„ ì²˜ë¦¬, í™œì„± ìŠ¤íŠ¸ë¦¼: {active_streams}ê°œ")
                    
    except Exception as e:
        logger.error(f"ìº¡ì²˜ ì›Œì»¤ ì˜¤ë¥˜: {e}")
    finally:
        for stream_id, cap in caps.items():
            cap.release()
        total_frames = sum(frame_counts.values())
        logger.info(f"ìº¡ì²˜ ì›Œì»¤ ì¢…ë£Œ - Worker {worker_id}, ì´ {total_frames}ê°œ í”„ë ˆì„")


def blur_worker_process(worker_id, blur_queues, save_queues, preview_queue, stats_dict, stop_event):
    """ê³µìœ  ë¸”ëŸ¬ ì›Œì»¤ - ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ íë¥¼ ìˆœí™˜ ì²˜ë¦¬"""
    logger = logging.getLogger(f"BLUR_WORKER_{worker_id}")
    current_pid = os.getpid()
    logger.info(f"ğŸ” ë¸”ëŸ¬ ì›Œì»¤ ì‹¤í–‰ ì¤‘ - PID: {current_pid}, Worker: {worker_id}")
    logger.info(f"   ğŸ†” í”„ë¡œì„¸ìŠ¤ ID: {current_pid}")
    logger.info(f"   ğŸ”§ ì›Œì»¤ ID: {worker_id}")
    logger.info(f"   ğŸ¯ ë‹¤ì¤‘ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ - {len(blur_queues)}ê°œ ë¸”ëŸ¬í, {len(save_queues)}ê°œ ì €ì¥í")
    
    processed_count = 0
    
    # ì›Œì»¤ë³„ ë¸”ëŸ¬ ëª¨ë“ˆ ìºì‹œ
    blur_modules = {}
    
    # ìŠ¤íŠ¸ë¦¼ë³„ ë¸”ëŸ¬ ìƒíƒœ ì €ì¥ (ì§€ì†ì„±ì„ ìœ„í•´)
    stream_blur_states = {}  # {stream_id: {'last_detection_result': {...}, 'last_detection_frame': 0}}
    
    def _apply_basic_blur_with_persistence(frame, stream_id, frame_number, blur_interval, worker_id, should_detect=True):
        """ê¸°ë³¸ ë¸”ëŸ¬ ì²˜ë¦¬ì— ì§€ì†ì„± ì ìš© (ê°€ìƒì˜ ì–¼êµ´ ì˜ì—­ ì‚¬ìš©)"""
        
        # ìŠ¤íŠ¸ë¦¼ë³„ ë¸”ëŸ¬ ìƒíƒœ ì´ˆê¸°í™”
        if stream_id not in stream_blur_states:
            stream_blur_states[stream_id] = {
                'last_detection_frame': 0,
                'last_blur_regions': []  # ë§ˆì§€ë§‰ ë¸”ëŸ¬ ì˜ì—­ë“¤
            }
        
        current_frame = frame_number
        
        if should_detect:
            # ìƒˆë¡œìš´ ê°€ìƒì˜ ì–¼êµ´ ì˜ì—­ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
            h, w = frame.shape[:2]
            # í™”ë©´ ì¤‘ì•™ ìƒë‹¨ì— ê°€ìƒì˜ ì–¼êµ´ ì˜ì—­ë“¤ ìƒì„±
            new_regions = [
                (w//4, h//6, w//4 + w//8, h//6 + h//8),      # ì²« ë²ˆì§¸ ì–¼êµ´
                (3*w//4 - w//8, h//6, 3*w//4, h//6 + h//8)   # ë‘ ë²ˆì§¸ ì–¼êµ´
            ]
            stream_blur_states[stream_id]['last_blur_regions'] = new_regions
            stream_blur_states[stream_id]['last_detection_frame'] = current_frame
            logger.info(f"Worker {worker_id}: Stream {stream_id} - âœ¨ ìƒˆë¡œìš´ ì–¼êµ´ íƒì§€ (í”„ë ˆì„ {current_frame}, ì˜ì—­: {len(new_regions)}ê°œ)")
        else:
            logger.info(f"Worker {worker_id}: Stream {stream_id} - ğŸ”„ ì´ì „ ì–¼êµ´ ìœ„ì¹˜ ìœ ì§€ (í”„ë ˆì„ {current_frame}, ë§ˆì§€ë§‰ íƒì§€: í”„ë ˆì„ {stream_blur_states[stream_id]['last_detection_frame']})")
        
        # ì €ì¥ëœ ì–¼êµ´ ì˜ì—­ì— ë¸”ëŸ¬ ì ìš©
        processed_frame = frame.copy()
        blur_regions = stream_blur_states[stream_id]['last_blur_regions']
        
        applied_regions = 0
        for x1, y1, x2, y2 in blur_regions:
            # ì˜ì—­ ê²€ì¦
            h, w = frame.shape[:2]
            x1 = max(0, min(x1, w-1))
            y1 = max(0, min(y1, h-1))
            x2 = max(x1+1, min(x2, w))
            y2 = max(y1+1, min(y2, h))
            
            # í•´ë‹¹ ì˜ì—­ì— ë¸”ëŸ¬ ì ìš©
            roi = processed_frame[y1:y2, x1:x2]
            if roi.size > 0:
                blurred_roi = cv2.GaussianBlur(roi, (51, 51), 0)
                processed_frame[y1:y2, x1:x2] = blurred_roi
                applied_regions += 1
        
        logger.info(f"Worker {worker_id}: Stream {stream_id} - ğŸ¯ ë¸”ëŸ¬ ì ìš© ì™„ë£Œ (í”„ë ˆì„ {current_frame}, ì˜ì—­: {applied_regions}/{len(blur_regions)}ê°œ)")
        return processed_frame
    
    # í ìˆœí™˜ì„ ìœ„í•œ ë³€ìˆ˜
    queue_keys = list(blur_queues.keys())
    queue_index = 0
    
    try:
        while not stop_event.is_set():
            # ëª¨ë“  ë¸”ëŸ¬ íê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            any_queue_has_data = False
            for queue_key in queue_keys:
                if not blur_queues[queue_key].empty():
                    any_queue_has_data = True
                    break
            
            if not any_queue_has_data and stop_event.is_set():
                break
                
            try:
                # ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹ìœ¼ë¡œ í ì„ íƒ
                current_queue_key = queue_keys[queue_index]
                current_blur_queue = blur_queues[current_queue_key]
                current_save_queue = save_queues[current_queue_key]
                
                # ë‹¤ìŒ íë¡œ ì¸ë±ìŠ¤ ì´ë™
                queue_index = (queue_index + 1) % len(queue_keys)
                
                work_item = current_blur_queue.get(timeout=0.1)
                
                # work_item êµ¬ì¡° ê²€ì¦
                if not isinstance(work_item, dict):
                    logger.warning(f"Worker {worker_id}: ì˜ëª»ëœ work_item í˜•ì‹")
                    continue
                
                # í•„ìˆ˜ í‚¤ í™•ì¸
                required_keys = ['frame', 'blur_module_path', 'stream_id', 'thread_id']
                missing_keys = [key for key in required_keys if key not in work_item]
                if missing_keys:
                    logger.warning(f"Worker {worker_id}: work_itemì— ëˆ„ë½ëœ í‚¤ - {missing_keys}")
                    continue
                
                frame = work_item['frame']
                blur_module_path = work_item['blur_module_path']
                stream_id = work_item['stream_id']
                thread_id = work_item['thread_id']
                timestamp = work_item.get('timestamp', datetime.now())
                frame_number = work_item.get('frame_number', 0)
                
                # ë¸”ëŸ¬ ëª¨ë“ˆ ë¡œë“œ (ìºì‹œ ì‚¬ìš©)
                blur_module = None
                if blur_module_path and blur_module_path not in blur_modules:
                    try:
                        logger.info(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ ë¡œë“œ ì‹œë„ (ìºì‹œ) - ê²½ë¡œ: {blur_module_path}")
                        
                        # íŒŒì¼ ì¡´ì¬ í™•ì¸
                        if not os.path.exists(blur_module_path):
                            logger.error(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ - {blur_module_path}")
                            blur_modules[blur_module_path] = None
                        else:
                            spec = importlib.util.spec_from_file_location(f"blur_module_{worker_id}_{stream_id}", blur_module_path)
                            blur_module = importlib.util.module_from_spec(spec)
                            spec.loader.exec_module(blur_module)
                            
                            if hasattr(blur_module, 'HeadBlurrer'):
                                logger.info(f"Worker {worker_id}: HeadBlurrer í´ë˜ìŠ¤ ë°œê²¬ (ë¸”ëŸ¬ ì›Œì»¤)")
                                try:
                                    head_blurrer = blur_module.HeadBlurrer()
                                    blur_module.apply_blur = lambda frame: head_blurrer.process_frame(frame)
                                    logger.info(f"Worker {worker_id}: HeadBlurrer ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ (ë¸”ëŸ¬ ì›Œì»¤)")
                                except Exception as init_error:
                                    logger.error(f"Worker {worker_id}: HeadBlurrer ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ (ë¸”ëŸ¬ ì›Œì»¤) - {init_error}")
                                    logger.info(f"Worker {worker_id}: ê¸°ë³¸ ë¸”ëŸ¬ ì²˜ë¦¬ë¡œ ëŒ€ì²´ (ë¸”ëŸ¬ ì›Œì»¤)")
                                    blur_module = None
                            else:
                                logger.warning(f"Worker {worker_id}: HeadBlurrer í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (ë¸”ëŸ¬ ì›Œì»¤)")
                                available_attrs = [attr for attr in dir(blur_module) if not attr.startswith('_')]
                                logger.info(f"Worker {worker_id}: ì‚¬ìš© ê°€ëŠ¥í•œ ì†ì„±ë“¤: {available_attrs}")
                            
                            blur_modules[blur_module_path] = blur_module
                            logger.info(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ (ìºì‹œ ì €ì¥)")
                    except Exception as e:
                        logger.error(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨ - {e}")
                        import traceback
                        logger.error(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨ ìƒì„¸ - {traceback.format_exc()}")
                        blur_modules[blur_module_path] = None
                else:
                    blur_module = blur_modules.get(blur_module_path)
                    if blur_module_path:
                        logger.debug(f"Worker {worker_id}: ë¸”ëŸ¬ ëª¨ë“ˆ ìºì‹œì—ì„œ ê°€ì ¸ì˜´ - {blur_module is not None}")
                
                # ë¸”ëŸ¬ ì²˜ë¦¬ (ì§€ì†ì„± í¬í•¨) - ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬
                should_detect = work_item.get('should_detect', True)  # íƒì§€ ìˆ˜í–‰ ì—¬ë¶€
                blur_interval = work_item.get('blur_interval', 3)  # íƒì§€ ê°„ê²©
                
                # ë¸”ëŸ¬ ì²˜ë¦¬ëŠ” í•­ìƒ ìˆ˜í–‰ (ì§€ì†ì„±ì„ ìœ„í•´)
                if blur_module and hasattr(blur_module, 'apply_blur'):
                    try:
                        # ìŠ¤íŠ¸ë¦¼ë³„ ë¸”ëŸ¬ ìƒíƒœ ì´ˆê¸°í™”
                        if stream_id not in stream_blur_states:
                            stream_blur_states[stream_id] = {
                                'last_detection_frame': 0,
                                'head_blurrer': None
                            }
                        
                        # HeadBlurrer ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ìŠ¤íŠ¸ë¦¼ë³„)
                        if stream_blur_states[stream_id]['head_blurrer'] is None:
                            if hasattr(blur_module, 'HeadBlurrer'):
                                try:
                                    stream_blur_states[stream_id]['head_blurrer'] = blur_module.HeadBlurrer()
                                    logger.info(f"Worker {worker_id}: ìŠ¤íŠ¸ë¦¼ {stream_id}ìš© HeadBlurrer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
                                except Exception as e:
                                    logger.error(f"Worker {worker_id}: HeadBlurrer ìƒì„± ì‹¤íŒ¨ - {e}")
                                    stream_blur_states[stream_id]['head_blurrer'] = 'failed'
                        
                        # HeadBlurrer ì‚¬ìš© (ì§€ì†ì„± ìˆëŠ” ë¸”ëŸ¬)
                        if (stream_blur_states[stream_id]['head_blurrer'] and 
                            stream_blur_states[stream_id]['head_blurrer'] != 'failed'):
                            
                            head_blurrer = stream_blur_states[stream_id]['head_blurrer']
                            
                            # ìº¡ì²˜ ì›Œì»¤ì—ì„œ ì „ë‹¬ë°›ì€ should_detect ì‚¬ìš©
                            if should_detect:
                                logger.debug(f"Worker {worker_id}: Stream {stream_id} - ìƒˆë¡œìš´ íƒì§€ ìˆ˜í–‰ (í”„ë ˆì„ {frame_number})")
                            else:
                                logger.debug(f"Worker {worker_id}: Stream {stream_id} - ì´ì „ íƒì§€ ê²°ê³¼ ì‚¬ìš© (í”„ë ˆì„ {frame_number})")
                            
                            # HeadBlurrerì˜ process_frame ë©”ì„œë“œ ì‚¬ìš© (should_detect ë§¤ê°œë³€ìˆ˜ë¡œ ì œì–´)
                            processed_frame = head_blurrer.process_frame(
                                frame, 
                                should_detect=should_detect,
                                blur_strength=0.01
                            )
                        else:
                            # HeadBlurrer ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¸”ëŸ¬ ì‚¬ìš©
                            processed_frame = blur_module.apply_blur(frame)
                        
                    except Exception as e:
                        logger.error(f"Worker {worker_id}: ì§€ì†ì„± ë¸”ëŸ¬ ì²˜ë¦¬ ì˜¤ë¥˜ - {e}")
                        # ê¸°ë³¸ ë¸”ëŸ¬ ì²˜ë¦¬ë„ ì§€ì†ì„± ì ìš©
                        processed_frame = _apply_basic_blur_with_persistence(
                            frame, stream_id, frame_number, blur_interval, worker_id, should_detect
                        )
                else:
                    # ë¸”ëŸ¬ ëª¨ë“ˆì´ ì—†ì„ ë•ŒëŠ” ì›ë³¸ í”„ë ˆì„ ì‚¬ìš©
                    processed_frame = frame
                
                # ì˜¤ë²„ë ˆì´ ì²˜ë¦¬
                overlay_enabled = work_item.get('overlay_enabled', False)
                if overlay_enabled:
                    current_time = timestamp.strftime("%Y-%m-%d %H:%M:%S")
                    
                    overlay_lines = [
                        f"Frame: {frame_number:06d}",
                        f"Time: {current_time}",
                        f"Thread: {thread_id}"
                    ]
                    
                    for i, line in enumerate(overlay_lines):
                        y_pos = 25 + i * 25
                        cv2.putText(processed_frame, line, (10, y_pos), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1, cv2.LINE_AA)
                
                # ì €ì¥ íë¡œ ì „ì†¡
                save_enabled = work_item.get('save_enabled', True)
                if save_enabled:
                    save_item = {
                        'stream_id': stream_id,
                        'thread_id': thread_id,
                        'frame': processed_frame,
                        'timestamp': timestamp,
                        'frame_number': frame_number,
                        'save_path': work_item.get('save_path', './output/'),
                        'save_format': work_item.get('save_format', 'mp4'),
                        'save_interval': work_item.get('save_interval', 300),
                        'save_interval_seconds': work_item.get('save_interval_seconds', 20)
                    }
                    
                    try:
                        current_save_queue.put_nowait(save_item)
                    except queue.Full:
                        try:
                            current_save_queue.get_nowait()
                            current_save_queue.put_nowait(save_item)
                            logger.warning(f"Worker {worker_id}: Stream {stream_id} ì €ì¥í ì˜¤ë²„í”Œë¡œìš°")
                        except:
                            pass
                
                # ë¯¸ë¦¬ë³´ê¸° íë¡œ ì „ì†¡
                preview_enabled = work_item.get('preview_enabled', True)
                if preview_enabled and frame_number % 3 == 0:
                    try:
                        h, w = processed_frame.shape[:2]
                        if w > 320:
                            new_w = 320
                            new_h = int(h * 320 / w)
                            preview_frame = cv2.resize(processed_frame, (new_w, new_h))
                        else:
                            preview_frame = processed_frame
                        
                        preview_queue.put_nowait((stream_id, preview_frame.copy(), 
                                                f"Blurred Thread {thread_id}"))
                    except queue.Full:
                        pass
                    except Exception as e:
                        logger.debug(f"Worker {worker_id}: ë¯¸ë¦¬ë³´ê¸° í ì „ì†¡ ì‹¤íŒ¨ - {e}")
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                stats_dict[f'{stream_id}_processed'] = stats_dict.get(f'{stream_id}_processed', 0) + 1
                processed_count += 1
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                if processed_count % 100 == 0:
                    import gc
                    gc.collect()
                    total_save_queue_size = sum(q.qsize() for q in save_queues.values())
                    logger.info(f"Worker {worker_id}: {processed_count}í”„ë ˆì„ ì²˜ë¦¬, ì´ ì €ì¥í: {total_save_queue_size}")
                        
            except queue.Empty:
                time.sleep(0.1)
                continue
            except Exception as e:
                logger.error(f"ë¸”ëŸ¬ ì›Œì»¤ ì˜¤ë¥˜: {e}")
                continue
                
    except Exception as e:
        logger.error(f"ë¸”ëŸ¬ ì›Œì»¤ ì˜¤ë¥˜: {e}")
    finally:
        logger.info(f"ë¸”ëŸ¬ ì›Œì»¤ ì¢…ë£Œ - Worker {worker_id}, ì²˜ë¦¬: {processed_count}")


def save_worker_process(worker_id, save_queues, stats_dict, stop_event, base_output_dir, config, shared_stream_last_save_times, stream_timing_lock):
    """ê³µìœ  ì €ì¥ ì›Œì»¤ - ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ íë¥¼ ìˆœí™˜ ì²˜ë¦¬"""
    logger = logging.getLogger(f"SAVE_WORKER_{worker_id}")
    current_pid = os.getpid()
    logger.info(f"ğŸ’¾ ì €ì¥ ì›Œì»¤ ì‹¤í–‰ ì¤‘ - PID: {current_pid}, Worker: {worker_id}")
    logger.info(f"   ğŸ†” í”„ë¡œì„¸ìŠ¤ ID: {current_pid}")
    logger.info(f"   ğŸ”§ ì›Œì»¤ ID: {worker_id}")
    logger.info(f"   ğŸ“ ì €ì¥ ê²½ë¡œ: {base_output_dir}")
    logger.info(f"   ğŸ¯ ë‹¤ì¤‘ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ - {len(save_queues)}ê°œ ì €ì¥í")
    
    saved_count = 0
    video_writers = {}
    frame_counts = {}
    file_counters = {}
    video_frame_counts = {}
    stream_dirs = {}
    file_start_times = {}  # ê° íŒŒì¼ì˜ ì‹œì‘ ì‹œê°„ ì¶”ì 
    
    # 15fps ì €ì¥ ì œí•œì„ ìœ„í•œ ê¸€ë¡œë²Œ ê³µìœ  íƒ€ì´ë¨¸
    target_fps = 15.0
    frame_interval = 1.0 / target_fps
    
    # í ìˆœí™˜ì„ ìœ„í•œ ë³€ìˆ˜
    queue_keys = list(save_queues.keys())
    queue_index = 0
    
    try:
        while not stop_event.is_set():
            # ëª¨ë“  ì €ì¥ íê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            any_queue_has_data = False
            for queue_key in queue_keys:
                if not save_queues[queue_key].empty():
                    any_queue_has_data = True
                    break
            
            if not any_queue_has_data and stop_event.is_set():
                break
                
            try:
                # ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹ìœ¼ë¡œ í ì„ íƒ
                current_queue_key = queue_keys[queue_index]
                current_save_queue = save_queues[current_queue_key]
                
                # ë‹¤ìŒ íë¡œ ì¸ë±ìŠ¤ ì´ë™
                queue_index = (queue_index + 1) % len(queue_keys)
                
                save_item = current_save_queue.get(timeout=0.1)
                
                stream_id = save_item['stream_id']
                frame = save_item['frame']
                timestamp = save_item['timestamp']
                save_path = save_item.get('save_path', './output/')
                save_format = save_item.get('save_format', 'mp4')
                save_interval = save_item.get('save_interval', 300)
                save_interval_seconds = save_item.get('save_interval_seconds', 20)  # ì‹œê°„ ê¸°ì¤€ íŒŒì¼ ë¶„í• 
                
                # ìŠ¤íŠ¸ë¦¼ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
                if stream_id not in stream_dirs:
                    stream_dir = os.path.join(base_output_dir, stream_id)
                    os.makedirs(stream_dir, exist_ok=True)
                    stream_dirs[stream_id] = stream_dir
                    frame_counts[stream_id] = 0
                    file_counters[stream_id] = 0
                    video_frame_counts[stream_id] = 0
                    # file_start_timesëŠ” ì²« ë²ˆì§¸ íŒŒì¼ ìƒì„± ì‹œì— ì„¤ì •ë¨

                frame_counts[stream_id] += 1
                
                # 15fps ì œì–´ (ìŠ¤íŠ¸ë¦¼ë³„ Lock ì‚¬ìš©)
                should_save_frame = False
                with stream_timing_lock:
                    current_time = time.time()
                    last_save_time = shared_stream_last_save_times.get(stream_id, 0.0)
                    time_since_last_save = current_time - last_save_time
                    
                    if time_since_last_save >= frame_interval:
                        shared_stream_last_save_times[stream_id] = current_time
                        should_save_frame = True
                        logger.debug(f"SAVE_WORKER_{worker_id}: Stream {stream_id} - í”„ë ˆì„ ì €ì¥ ìŠ¹ì¸ (ê°„ê²©: {time_since_last_save:.3f}s)")
                    else:
                        logger.debug(f"SAVE_WORKER_{worker_id}: Stream {stream_id} - í”„ë ˆì„ ìŠ¤í‚µ (ê°„ê²©: {time_since_last_save:.3f}s)")
                
                if not should_save_frame:
                    continue
                
                # ë¹„ë””ì˜¤ íŒŒì¼ ë¶„í•  ë¡œì§
                if save_format in ['mp4', 'mkv', 'webm', 'avi']:
                    # ìƒˆ ë¹„ë””ì˜¤ íŒŒì¼ ì‹œì‘ ì¡°ê±´ (í”„ë ˆì„ ìˆ˜ ê¸°ì¤€ ë˜ëŠ” ì‹œê°„ ê¸°ì¤€)
                    should_create_new_file = False
                    
                    if stream_id not in video_writers or not video_writers[stream_id].isOpened():
                        should_create_new_file = True
                        reason = "ì²« íŒŒì¼ ë˜ëŠ” Writer ì—†ìŒ"
                    elif video_frame_counts[stream_id] >= save_interval:
                        should_create_new_file = True
                        reason = f"í”„ë ˆì„ ìˆ˜ ì´ˆê³¼ ({video_frame_counts[stream_id]}/{save_interval})"
                    elif stream_id in file_start_times:
                        # ì‹œê°„ ê¸°ì¤€ í™•ì¸
                        time_elapsed = (timestamp - file_start_times[stream_id]).total_seconds()
                        if time_elapsed >= save_interval_seconds:
                            should_create_new_file = True
                            reason = f"ì‹œê°„ ì´ˆê³¼ ({time_elapsed:.1f}s/{save_interval_seconds}s)"
                    
                    if should_create_new_file:
                        
                        # ê¸°ì¡´ writer ì¢…ë£Œ
                        if stream_id in video_writers:
                            try:
                                video_writers[stream_id].release()
                                logger.info(f"Stream {stream_id}: ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ - {video_frame_counts[stream_id]}í”„ë ˆì„")
                            except:
                                pass
                            del video_writers[stream_id]
                        
                        # ìƒˆ íŒŒì¼ ìƒì„±
                        file_counters[stream_id] += 1
                        video_frame_counts[stream_id] = 0
                        file_start_times[stream_id] = timestamp  # íŒŒì¼ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                        
                        timestamp_str = timestamp.strftime("%Y%m%d_%H%M%S")
                        filename = f"{stream_id}_{timestamp_str}_part{file_counters[stream_id]:03d}.{save_format}"
                        filepath = os.path.join(stream_dirs[stream_id], filename)
                        
                        height, width = frame.shape[:2]
                        fps = 15.0
                        
                        # OpenCV VideoWriter ìƒì„± (í•´ìƒë„ ìˆœì„œ ì£¼ì˜: width, height)
                        # mp4v ì½”ë± ì‚¬ìš© (ê°€ì¥ ì•ˆì •ì )
                        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                        writer = cv2.VideoWriter(filepath, fourcc, fps, (width, height))
                        codec_used = 'mp4v'
                        logger.info(f"Stream {stream_id}: ë¹„ë””ì˜¤ ìƒì„± ì‹œë„ - í”„ë ˆì„ í¬ê¸°: {frame.shape}, Writer í¬ê¸°: ({width}, {height})")
                        
                        if writer.isOpened():
                            video_writers[stream_id] = writer
                            logger.info(f"Stream {stream_id}: âœ… ìƒˆ ë¹„ë””ì˜¤ íŒŒì¼ ì‹œì‘ - {filename} (ì½”ë±: {codec_used}, í•´ìƒë„: {width}x{height}, ì´ìœ : {reason})")
                        else:
                            logger.error(f"Stream {stream_id}: VideoWriter ìƒì„± ì‹¤íŒ¨ - ëª¨ë“  ì½”ë± ì‹œë„ ì‹¤íŒ¨ (XVID, X264, mp4v)")
                            logger.error(f"Stream {stream_id}: íŒŒì¼ ê²½ë¡œ: {filepath}")
                            logger.error(f"Stream {stream_id}: í•´ìƒë„: {width}x{height}, FPS: {fps}")
                            writer.release()
                            continue
                    
                    # í”„ë ˆì„ ì €ì¥ (OpenCV write() ë°˜í™˜ê°’ì€ ë¶€ì •í™•í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰)
                    if stream_id in video_writers and video_writers[stream_id].isOpened():
                        try:
                            # í”„ë ˆì„ ì“°ê¸° (ë°˜í™˜ê°’ ë¬´ì‹œ)
                            video_writers[stream_id].write(frame)
                            
                            # ì„±ê³µìœ¼ë¡œ ê°„ì£¼í•˜ê³  ì¹´ìš´í„° ì¦ê°€
                            video_frame_counts[stream_id] += 1
                            saved_count += 1
                            stats_dict[f'{stream_id}_saved'] = stats_dict.get(f'{stream_id}_saved', 0) + 1
                            
                            if saved_count % 25 == 0:
                                total_queue_size = sum(q.qsize() for q in save_queues.values())
                                logger.info(f"Worker {worker_id}: {saved_count}í”„ë ˆì„ ì €ì¥ (15fps ì œì–´), ì´ í: {total_queue_size}")
                                    
                        except Exception as e:
                            logger.error(f"Stream {stream_id}: í”„ë ˆì„ ì“°ê¸° ì¤‘ ì˜¤ë¥˜ - {e}")
                            if stream_id in video_writers:
                                try:
                                    video_writers[stream_id].release()
                                except:
                                    pass
                                del video_writers[stream_id]
                        
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"ì €ì¥ ì›Œì»¤ ì˜¤ë¥˜: {e}")
                continue
                
    except Exception as e:
        logger.error(f"ì €ì¥ ì›Œì»¤ ì˜¤ë¥˜: {e}")
    finally:
        # ëª¨ë“  ë¹„ë””ì˜¤ writer ì •ë¦¬
        for stream_id, writer in video_writers.items():
            try:
                writer.release()
                logger.info(f"Stream {stream_id}: ìµœì¢… ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ")
            except:
                pass
        logger.info(f"ì €ì¥ ì›Œì»¤ ì¢…ë£Œ - Worker {worker_id}, ì €ì¥: {saved_count}")


def file_move_worker_process(worker_id, file_move_queue, stats_dict, stop_event, ssd_path, hdd_path, temp_prefix):
    """íŒŒì¼ ì´ë™ ì›Œì»¤ (SSD â†’ HDD)"""
    logger = logging.getLogger(f"FILE_MOVE_WORKER_{worker_id}")
    current_pid = os.getpid()
    logger.info(f"ğŸš› íŒŒì¼ ì´ë™ ì›Œì»¤ ì‹¤í–‰ ì¤‘ - PID: {current_pid}, Worker: {worker_id}")
    logger.info(f"   ğŸ†” í”„ë¡œì„¸ìŠ¤ ID: {current_pid}")
    logger.info(f"   ğŸ”§ ì›Œì»¤ ID: {worker_id}")
    logger.info(f"   ğŸ“‚ SSD ê²½ë¡œ: {ssd_path}")
    logger.info(f"   ğŸ“ HDD ê²½ë¡œ: {hdd_path}")
    logger.info(f"   ğŸ”„ 2ë‹¨ê³„ ì €ì¥ íŒŒì¼ ì´ë™ ì‹œì‘")
    
    moved_count = 0
    
    # ì‹œê°„ ê¸°ë°˜ ë””ë ‰í† ë¦¬ êµ¬ì¡° í•¨ìˆ˜
    def get_time_based_directory_from_filename(filename):
        """íŒŒì¼ëª…ì—ì„œ ì‹œê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ YYYY/MM/DD/HH í˜•ì‹ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ ìƒì„±"""
        try:
            # íŒŒì¼ëª… í˜•ì‹: shipname_streamid_YYYYMMDD_HHMMSS.ext
            logger.debug(f"Worker {worker_id}: íŒŒì¼ëª… íŒŒì‹± ì‹œì‘ - {filename}")
            
            # í™•ì¥ì ì œê±°
            name_without_ext = os.path.splitext(filename)[0]
            parts = name_without_ext.split('_')
            
            logger.debug(f"Worker {worker_id}: íŒŒì¼ëª… íŒŒíŠ¸ - {parts}")
            
            if len(parts) >= 4:  # shipname, streamid, YYYYMMDD, HHMMSS
                # YYYYMMDD ë¶€ë¶„ ì°¾ê¸° (4ë²ˆì§¸ íŒŒíŠ¸)
                date_str = None
                for part in parts:
                    if isinstance(part, str) and len(part) == 8 and part.isdigit():
                        date_str = part
                        logger.debug(f"Worker {worker_id}: ë‚ ì§œ ë¬¸ìì—´ ì°¾ìŒ - {date_str}")
                        break
                if not date_str:
                    logger.warning(f"Worker {worker_id}: ë‚ ì§œ ë¬¸ìì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - {parts}")
                    return None
                
                # HHMMSS ë¶€ë¶„ ì°¾ê¸° (4ë²ˆì§¸ íŒŒíŠ¸)
                time_str = None
                for part in parts:
                    if isinstance(part, str) and len(part) == 6 and part.isdigit():
                        time_str = part
                        logger.debug(f"Worker {worker_id}: ì‹œê°„ ë¬¸ìì—´ ì°¾ìŒ - {time_str}")
                        break
                else:
                    logger.warning(f"Worker {worker_id}: ì‹œê°„ ë¬¸ìì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - {parts}")
                    return None
                
                # ì‹œê°„ ì •ë³´ íŒŒì‹±
                year = int(date_str[:4])
                month = int(date_str[4:6])
                day = int(date_str[6:8])
                hour = int(time_str[:2])
                
                time_dir = os.path.join(
                    str(year),
                    f"{month:02d}",
                    f"{day:02d}",
                    f"{hour:02d}"
                )
                
                logger.info(f"Worker {worker_id}: ì‹œê°„ ê¸°ë°˜ ë””ë ‰í† ë¦¬ ìƒì„± ì„±ê³µ - {time_dir}")
                return time_dir
            else:
                logger.warning(f"Worker {worker_id}: íŒŒì¼ëª… íŒŒíŠ¸ê°€ ë¶€ì¡±í•¨ - {parts}")
                return None
                
        except Exception as e:
            logger.error(f"Worker {worker_id}: íŒŒì¼ëª…ì—ì„œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨ - {filename}: {e}")
            return None
    
    try:
        # HDD ìµœì¢… ì €ì¥ ê²½ë¡œ ìƒì„±
        os.makedirs(hdd_path, exist_ok=True)
        
        while not stop_event.is_set() or not file_move_queue.empty():
            try:
                move_item = file_move_queue.get(timeout=1.0)
                logger.info(f"Worker {worker_id}: íŒŒì¼ ì´ë™ ì‘ì—… ìˆ˜ì‹  - {move_item}")
                
                if not isinstance(move_item, dict):
                    logger.warning(f"Worker {worker_id}: ì˜ëª»ëœ move_item í˜•ì‹ - {type(move_item)}")
                    continue
                
                # move_item êµ¬ì¡°: {'temp_filepath': str, 'final_filename': str, 'stream_id': str}
                temp_filepath = move_item['temp_filepath']
                final_filename = move_item['final_filename']
                stream_id = move_item['stream_id']
                
                logger.info(f"Worker {worker_id}: íŒŒì¼ ì´ë™ ì‹œì‘ - {final_filename} (ìŠ¤íŠ¸ë¦¼: {stream_id})")
                
                # ì„ì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                if not os.path.exists(temp_filepath):
                    logger.warning(f"Worker {worker_id}: ì„ì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ - {temp_filepath}")
                    continue
                
                # HDD ì‹œê°„ ê¸°ë°˜ ë””ë ‰í† ë¦¬ ìƒì„± (ìŠ¤íŠ¸ë¦¼ë³„ êµ¬ë¶„ ì—†ìŒ)
                time_based_dir = get_time_based_directory_from_filename(final_filename)
                if time_based_dir:
                    hdd_time_dir = os.path.join(hdd_path, time_based_dir)
                    os.makedirs(hdd_time_dir, exist_ok=True)
                    
                    # ìµœì¢… íŒŒì¼ ê²½ë¡œ
                    final_filepath = os.path.join(hdd_time_dir, final_filename)
                    logger.debug(f"Worker {worker_id}: ì‹œê°„ ê¸°ë°˜ ë””ë ‰í† ë¦¬ ì‚¬ìš© - {time_based_dir}")
                else:
                    # ì‹œê°„ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
                    hdd_default_dir = os.path.join(hdd_path, "unknown_time")
                    os.makedirs(hdd_default_dir, exist_ok=True)
                    final_filepath = os.path.join(hdd_default_dir, final_filename)
                    logger.warning(f"Worker {worker_id}: ì‹œê°„ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì‚¬ìš© - {final_filename}")
                
                # íŒŒì¼ ì´ë™ ì‹œë„
                try:
                    import shutil
                    logger.info(f"Worker {worker_id}: íŒŒì¼ ì´ë™ ì‹œì‘ - {temp_filepath} â†’ {final_filepath}")
                    
                    # íŒŒì¼ í¬ê¸° í™•ì¸
                    if os.path.exists(temp_filepath):
                        file_size = os.path.getsize(temp_filepath)
                        logger.info(f"Worker {worker_id}: ì´ë™í•  íŒŒì¼ í¬ê¸° - {file_size} bytes")
                    
                    shutil.move(temp_filepath, final_filepath)
                    moved_count += 1
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    stats_dict[f'{stream_id}_moved'] = stats_dict.get(f'{stream_id}_moved', 0) + 1
                    
                    logger.info(f"Worker {worker_id}: âœ… íŒŒì¼ ì´ë™ ì™„ë£Œ - {final_filename}")
                    
                    if moved_count % 10 == 0:
                        logger.info(f"Worker {worker_id}: {moved_count}ê°œ íŒŒì¼ ì´ë™ ì™„ë£Œ, í: {file_move_queue.qsize()}")
                    
                except Exception as move_error:
                    logger.error(f"Worker {worker_id}: âŒ íŒŒì¼ ì´ë™ ì‹¤íŒ¨ - {temp_filepath} â†’ {final_filepath}")
                    logger.error(f"Worker {worker_id}: ì´ë™ ì˜¤ë¥˜: {move_error}")
                    
                    # ì´ë™ ì‹¤íŒ¨ ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    try:
                        if os.path.exists(temp_filepath):
                            os.remove(temp_filepath)
                            logger.warning(f"Worker {worker_id}: ì´ë™ ì‹¤íŒ¨í•œ ì„ì‹œ íŒŒì¼ ì •ë¦¬ë¨ - {temp_filepath}")
                    except Exception as cleanup_error:
                        logger.error(f"Worker {worker_id}: ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨ - {cleanup_error}")
                        
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"íŒŒì¼ ì´ë™ ì›Œì»¤ ì˜¤ë¥˜: {e}")
                continue
                
    except Exception as e:
        logger.error(f"íŒŒì¼ ì´ë™ ì›Œì»¤ ì˜¤ë¥˜: {e}")
    finally:
        logger.info(f"íŒŒì¼ ì´ë™ ì›Œì»¤ ì¢…ë£Œ - Worker {worker_id}, ì´ë™: {moved_count}")


def file_monitor_worker_process(file_move_queue, stats_dict, stop_event, ssd_path, temp_prefix):
    """íŒŒì¼ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„° ì›Œì»¤ (inotify ê¸°ë°˜)"""
    logger = logging.getLogger("FILE_MONITOR_WORKER")
    current_pid = os.getpid()
    logger.info(f"ğŸ‘ï¸ íŒŒì¼ ëª¨ë‹ˆí„° ì›Œì»¤ ì‹¤í–‰ ì¤‘ - PID: {current_pid}")
    logger.info(f"   ğŸ†” í”„ë¡œì„¸ìŠ¤ ID: {current_pid}")
    logger.info(f"   ğŸ“‚ ëª¨ë‹ˆí„°ë§ ê²½ë¡œ: {ssd_path}")
    logger.info(f"   ğŸ·ï¸ ì„ì‹œ íŒŒì¼ ì ‘ë‘ì‚¬: {temp_prefix}")
    logger.info(f"   ğŸ”„ 2ë‹¨ê³„ ì €ì¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    logger.info(f"   ğŸ“Š file_move_queue ì¡´ì¬: {file_move_queue is not None}")
    logger.info(f"   ğŸ›‘ stop_event ìƒíƒœ: {stop_event.is_set()}")
    
    detected_count = 0
    
    try:
        # inotify ì‚¬ìš© ê°€ëŠ¥ í™•ì¸
        try:
            import inotify_simple
            from inotify_simple import INotify, flags
            logger.info("âœ… inotify_simple ëª¨ë“ˆ ì‚¬ìš©")
        except ImportError:
            # watchdog ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (fallback)
            try:
                from watchdog.observers import Observer
                from watchdog.events import FileSystemEventHandler
                logger.info("âœ… watchdog ëª¨ë“ˆ ì‚¬ìš© (fallback)")
                use_watchdog = True
            except ImportError:
                logger.error("âŒ inotify_simpleê³¼ watchdog ëª¨ë“ˆì„ ëª¨ë‘ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                logger.error("ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install inotify_simple ë˜ëŠ” pip install watchdog")
                return
        else:
            use_watchdog = False
        
        # SSD ê²½ë¡œ ìƒì„±
        os.makedirs(ssd_path, exist_ok=True)
        
        if use_watchdog:
            # watchdog ê¸°ë°˜ ëª¨ë‹ˆí„°ë§
            class FileEventHandler(FileSystemEventHandler):
                def __init__(self, monitor_worker):
                    self.monitor_worker = monitor_worker
                
                def on_moved(self, event):
                    # íŒŒì¼ ì´ë¦„ ë³€ê²½ ì´ë²¤íŠ¸ (t_ ì ‘ë‘ì‚¬ ì œê±°)
                    if not event.is_directory:
                        logger.info(f"ğŸ‘ï¸ watchdog MOVED ì´ë²¤íŠ¸ ê°ì§€: {event.dest_path}")
                        self.monitor_worker.handle_file_event(event.dest_path, "MOVED_TO")
                
                def on_created(self, event):
                    # ìƒˆ íŒŒì¼ ìƒì„± ì´ë²¤íŠ¸
                    if not event.is_directory:
                        logger.info(f"ğŸ‘ï¸ watchdog CREATED ì´ë²¤íŠ¸ ê°ì§€: {event.src_path}")
                        self.monitor_worker.handle_file_event(event.src_path, "CREATE")
            
            # ëª¨ë‹ˆí„° ì›Œì»¤ í´ë˜ìŠ¤
            class WatchdogMonitor:
                def __init__(self):
                    self.detected_count = 0
                
                def handle_file_event(self, filepath, event_type):
                    nonlocal detected_count, file_move_queue, stats_dict, logger, temp_prefix
                    
                    try:
                        filename = os.path.basename(filepath)
                        logger.info(f"ğŸ‘ï¸ íŒŒì¼ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹œì‘: {filename} (íƒ€ì…: {event_type})")
                        
                        # ë¹„ë””ì˜¤ íŒŒì¼ì¸ì§€ í™•ì¸ (temp_prefix ì œê±° í›„ ê°ì§€)
                        if filename.lower().endswith(('.mp4', '.mkv', '.avi', '.webm')):
                            logger.info(f"ğŸ‘ï¸ ë¹„ë””ì˜¤ íŒŒì¼ ê°ì§€: {filename}")
                            
                            # ìŠ¤íŠ¸ë¦¼ ID ì¶”ì¶œ
                            try:
                                name_without_ext = os.path.splitext(filename)[0]
                                parts = name_without_ext.split('_')
                                logger.info(f"ğŸ‘ï¸ íŒŒì¼ëª… íŒŒíŠ¸ ë¶„ì„: {parts}")
                                
                                if len(parts) >= 2:
                                    stream_id = parts[1]
                                    if not stream_id.startswith('stream'):
                                        logger.debug(f"ğŸ‘ï¸ ìŠ¤íŠ¸ë¦¼ IDê°€ ì•„ë‹˜: {stream_id}")
                                        return
                                    logger.info(f"ğŸ‘ï¸ ìŠ¤íŠ¸ë¦¼ ID ì¶”ì¶œ ì„±ê³µ: {stream_id}")
                                else:
                                    logger.warning(f"ğŸ‘ï¸ íŒŒì¼ëª… íŒŒíŠ¸ ë¶€ì¡±: {parts}")
                                    return
                            except Exception as e:
                                logger.error(f"ğŸ‘ï¸ ìŠ¤íŠ¸ë¦¼ ID ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                                return
                            
                            # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ê³  ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸
                            if os.path.exists(filepath) and os.access(filepath, os.R_OK):
                                file_size = os.path.getsize(filepath)
                                logger.info(f"ğŸ‘ï¸ íŒŒì¼ ì¡´ì¬ í™•ì¸: {filename} (í¬ê¸°: {file_size} bytes)")
                                
                                # ì•½ê°„ì˜ ëŒ€ê¸° (íŒŒì¼ ì“°ê¸° ì™„ë£Œ í™•ì¸)
                                time.sleep(0.5)
                                
                                if os.path.exists(filepath):
                                    move_item = {
                                        'temp_filepath': filepath,
                                        'final_filename': filename,
                                        'stream_id': stream_id
                                    }
                                    
                                    try:
                                        file_move_queue.put_nowait(move_item)
                                        detected_count += 1
                                        logger.info(f"ğŸ“ íŒŒì¼ ê°ì§€ë¨: {filename} (ì´ {detected_count}ê°œ)")
                                        
                                        if detected_count % 10 == 0:
                                            logger.info(f"ğŸ‘ï¸ ëª¨ë‹ˆí„°: {detected_count}ê°œ íŒŒì¼ ê°ì§€, ì´ë™í: {file_move_queue.qsize()}")
                                        
                                    except queue.Full:
                                        logger.warning(f"ğŸ‘ï¸ íŒŒì¼ ì´ë™ íê°€ ê°€ë“ì°¸ - {filename}")
                                        try:
                                            file_move_queue.get_nowait()
                                            file_move_queue.put_nowait(move_item)
                                        except:
                                            pass
                                else:
                                    logger.warning(f"ğŸ‘ï¸ íŒŒì¼ì´ ì‚¬ë¼ì§: {filename}")
                            else:
                                logger.warning(f"ğŸ‘ï¸ íŒŒì¼ ì ‘ê·¼ ë¶ˆê°€: {filename}")
                        else:
                            logger.debug(f"ğŸ‘ï¸ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì•„ë‹˜: {filename}")
                    
                    except Exception as e:
                        logger.error(f"ğŸ‘ï¸ íŒŒì¼ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            
            # watchdog ëª¨ë‹ˆí„°ë§ ì‹œì‘
            monitor = WatchdogMonitor()
            event_handler = FileEventHandler(monitor)
            observer = Observer()
            observer.schedule(event_handler, ssd_path, recursive=True)
            observer.start()
            
            logger.info("ğŸ‘ï¸ watchdog íŒŒì¼ ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨")
            
            try:
                while not stop_event.is_set():
                    time.sleep(1)
            finally:
                observer.stop()
                observer.join()
        
        else:
            # inotify ê¸°ë°˜ ëª¨ë‹ˆí„°ë§ (long implementation continues...)
            # Full implementation would continue here but truncated for space
            logger.info("inotify ëª¨ë‹ˆí„°ë§ êµ¬í˜„ (ìƒëµ)")
                
    except Exception as e:
        logger.error(f"íŒŒì¼ ëª¨ë‹ˆí„° ì›Œì»¤ ì˜¤ë¥˜: {e}")
    finally:
        logger.info(f"íŒŒì¼ ëª¨ë‹ˆí„° ì›Œì»¤ ì¢…ë£Œ - ê°ì§€: {detected_count}")