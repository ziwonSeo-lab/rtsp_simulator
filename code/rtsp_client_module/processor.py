"""
RTSP ë©€í‹°í”„ë¡œì„¸ì‹± í”„ë¡œì„¸ì„œ ëª¨ë“ˆ

SharedPoolRTSPProcessor í´ë˜ìŠ¤ë¥¼ í¬í•¨í•˜ì—¬ ë©€í‹°í”„ë¡œì„¸ì‹± í™˜ê²½ì—ì„œ
RTSP ìŠ¤íŠ¸ë¦¼ì„ ìº¡ì²˜, ì²˜ë¦¬, ì €ì¥í•˜ëŠ” ì‹œìŠ¤í…œì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

ì´ ëª¨ë“ˆì€ multi-process_rtsp.pyì—ì„œ ì¶”ì¶œë˜ì—ˆìœ¼ë©°,
ë…ë¦½ëœ ëª¨ë“ˆë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import os
import time
import logging
from multiprocessing import Manager, Queue, Process, Event
from typing import Dict, Any, Optional
import queue

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from .config import RTSPConfig
from .statistics import FrameCounter, ResourceMonitor, PerformanceProfiler
from .workers import rtsp_capture_process, blur_worker_process, save_worker_process, file_move_worker_process

logger = logging.getLogger(__name__)


class SharedPoolRTSPProcessor:
    """
    ê³µìœ  í’€ ê¸°ë°˜ RTSP ì²˜ë¦¬ ì‹œìŠ¤í…œ
    
    ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‚¬ìš©í•˜ì—¬ RTSP ìŠ¤íŠ¸ë¦¼ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ëŠ” í”„ë¡œì„¸ì„œì…ë‹ˆë‹¤.
    ìº¡ì²˜, ë¸”ëŸ¬ ì²˜ë¦¬, ì €ì¥ì„ ê°ê° ë³„ë„ì˜ í”„ë¡œì„¸ìŠ¤ì—ì„œ ìˆ˜í–‰í•˜ì—¬
    ë†’ì€ ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    Features:
    - ë©€í‹°í”„ë¡œì„¸ìŠ¤ ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬
    - ìŠ¤ë ˆë“œë³„ RTSP ì†ŒìŠ¤ í• ë‹¹
    - ì‹¤ì‹œê°„ í†µê³„ ë° ëª¨ë‹ˆí„°ë§
    - ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
    - ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
    """
    
    def __init__(self, config: RTSPConfig):
        """
        SharedPoolRTSPProcessor ì´ˆê¸°í™”
        
        Args:
            config (RTSPConfig): RTSP ì²˜ë¦¬ ì„¤ì •
        """
        self.config = config
        self.frame_counter = FrameCounter()
        self.resource_monitor = ResourceMonitor()
        self.performance_profiler = PerformanceProfiler()
        
        # ë©€í‹°í”„ë¡œì„¸ì‹± ìš”ì†Œë“¤
        self.manager = Manager()
        self.blur_queue = Queue(maxsize=config.blur_queue_size)
        self.save_queue = Queue(maxsize=config.save_queue_size)
        self.preview_queue = Queue(maxsize=config.preview_queue_size)
        self.stats_dict = self.manager.dict()
        self.stop_event = Event()
        
        # 2ë‹¨ê³„ ì €ì¥ì„ ìœ„í•œ íŒŒì¼ ì´ë™ í
        if hasattr(config, 'two_stage_storage') and config.two_stage_storage:
            self.file_move_queue = Queue(maxsize=getattr(config, 'file_move_queue_size', 100))
        else:
            self.file_move_queue = None
        
        # í”„ë¡œì„¸ìŠ¤ ë¦¬ìŠ¤íŠ¸
        self.capture_processes = []
        self.blur_processes = []
        self.save_processes = []
        self.file_move_processes = []
        
        self.running = False
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        if config.save_enabled:
            os.makedirs(config.save_path, exist_ok=True)
    
    def get_source_for_thread(self, thread_id: int) -> str:
        """
        ìŠ¤ë ˆë“œ IDì— ë”°ë¥¸ ì†ŒìŠ¤ ë°˜í™˜
        
        Args:
            thread_id (int): ìŠ¤ë ˆë“œ ID
            
        Returns:
            str: í• ë‹¹ëœ ì†ŒìŠ¤ URL ë˜ëŠ” ê²½ë¡œ
            
        Raises:
            ValueError: ì†ŒìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°
        """
        if not self.config.sources:
            raise ValueError("ì†ŒìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ìˆœí™˜ ë°©ì‹ìœ¼ë¡œ ì†ŒìŠ¤ í• ë‹¹
        source_index = thread_id % len(self.config.sources)
        return self.config.sources[source_index]
    
    def is_rtsp_source(self, source: str) -> bool:
        """
        RTSP ì†ŒìŠ¤ì¸ì§€ í™•ì¸
        
        Args:
            source (str): ì†ŒìŠ¤ URL ë˜ëŠ” ê²½ë¡œ
            
        Returns:
            bool: RTSP ì†ŒìŠ¤ ì—¬ë¶€
        """
        return source.lower().startswith(('rtsp://', 'http://', 'https://'))
    
    def extract_source_name(self, source: str) -> str:
        """
        ì†ŒìŠ¤ì—ì„œ ì´ë¦„ ì¶”ì¶œ
        
        Args:
            source (str): ì†ŒìŠ¤ URL ë˜ëŠ” ê²½ë¡œ
            
        Returns:
            str: ì¶”ì¶œëœ ì†ŒìŠ¤ ì´ë¦„
        """
        try:
            if self.is_rtsp_source(source):
                if '://' in source:
                    parts = source.split('://', 1)[1]
                    if '/' in parts:
                        return parts.split('/', 1)[1]
                    else:
                        return parts
            else:
                return os.path.basename(source)
            return source
        except:
            return source
    
    def start(self):
        """
        RTSP ì²˜ë¦¬ ì‹œìŠ¤í…œ ì‹œì‘
        
        ëª¨ë“  ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•˜ê³  ëª¨ë‹ˆí„°ë§ì„ í™œì„±í™”í•©ë‹ˆë‹¤.
        """
        logger.info("ê³µìœ  í’€ RTSP ì²˜ë¦¬ ì‹œìŠ¤í…œ ì‹œì‘")
        self.running = True
        
        self.resource_monitor.start_monitoring()
        self.performance_profiler.start_profile("total_processing")
        
        # ìŠ¤ë ˆë“œë³„ ìº¡ì²˜ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
        logger.info("=" * 60)
        logger.info("ğŸš€ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ - PID ì •ë³´ ì¶œë ¥")
        logger.info("=" * 60)
        
        for thread_id in range(self.config.thread_count):
            source = self.get_source_for_thread(thread_id)
            stream_id = f"stream_{thread_id+1}"
            
            proc = Process(
                target=rtsp_capture_process,
                args=(source, stream_id, thread_id, self.blur_queue, self.preview_queue, 
                      self.stats_dict, self.stop_event, self.config),
                name=f"Capture_{stream_id}"
            )
            proc.start()
            self.capture_processes.append(proc)
            
            logger.info(f"ğŸ“¹ ìº¡ì²˜ í”„ë¡œì„¸ìŠ¤ ì‹œì‘: {stream_id} (PID: {proc.pid}) - {source}")
        
        # ë¸”ëŸ¬ ì²˜ë¦¬ ì›Œì»¤ë“¤ ì‹œì‘
        logger.info("-" * 40)
        for i in range(self.config.blur_workers):
            proc = Process(
                target=blur_worker_process,
                args=(i+1, self.blur_queue, self.save_queue, self.preview_queue,
                      self.stats_dict, self.stop_event),
                name=f"BlurWorker_{i+1}"
            )
            proc.start()
            self.blur_processes.append(proc)
            logger.info(f"ğŸ” ë¸”ëŸ¬ ì›Œì»¤ ì‹œì‘: Worker {i+1} (PID: {proc.pid})")
        
        # ì €ì¥ ì›Œì»¤ë“¤ ì‹œì‘
        if self.config.save_enabled:
            logger.info("-" * 40)
            for i in range(self.config.save_workers):
                proc = Process(
                    target=save_worker_process,
                    args=(i+1, self.save_queue, self.stats_dict, 
                          self.stop_event, self.config.save_path, 
                          self.file_move_queue, self.config),
                    name=f"SaveWorker_{i+1}"
                )
                proc.start()
                self.save_processes.append(proc)
                logger.info(f"ğŸ’¾ ì €ì¥ ì›Œì»¤ ì‹œì‘: Worker {i+1} (PID: {proc.pid})")
        
        # íŒŒì¼ ì´ë™ ì›Œì»¤ë“¤ ì‹œì‘ (2ë‹¨ê³„ ì €ì¥ í™œì„±í™” ì‹œ)
        if (hasattr(self.config, 'two_stage_storage') and self.config.two_stage_storage and 
            self.file_move_queue is not None):
            logger.info("-" * 40)
            for i in range(getattr(self.config, 'file_move_workers', 2)):
                proc = Process(
                    target=file_move_worker_process,
                    args=(i+1, self.file_move_queue, self.stats_dict, 
                          self.stop_event, self.config.ssd_temp_path, 
                          self.config.hdd_final_path, self.config.temp_file_prefix),
                    name=f"FileMoveWorker_{i+1}"
                )
                proc.start()
                self.file_move_processes.append(proc)
                logger.info(f"ğŸš› íŒŒì¼ ì´ë™ ì›Œì»¤ ì‹œì‘: Worker {i+1} (PID: {proc.pid})")
        
        total = (len(self.capture_processes) + len(self.blur_processes) + 
                len(self.save_processes) + len(self.file_move_processes))
        logger.info("=" * 60)
        logger.info(f"âœ… ì´ {total}ê°œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì™„ë£Œ")
        logger.info(f"   ğŸ“¹ ìº¡ì²˜: {len(self.capture_processes)}ê°œ")
        logger.info(f"   ğŸ” ë¸”ëŸ¬: {len(self.blur_processes)}ê°œ")
        logger.info(f"   ğŸ’¾ ì €ì¥: {len(self.save_processes)}ê°œ")
        logger.info(f"   ğŸš› ì´ë™: {len(self.file_move_processes)}ê°œ")
        logger.info("=" * 60)
    
    def stop(self):
        """
        RTSP ì²˜ë¦¬ ì‹œìŠ¤í…œ ì¢…ë£Œ
        
        ëª¨ë“  ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•˜ê³  ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
        """
        logger.info("ê³µìœ  í’€ ì‹œìŠ¤í…œ ì¢…ë£Œ ì‹œì‘...")
        self.running = False
        
        self.performance_profiler.end_profile("total_processing")
        
        # ì¢…ë£Œ ì´ë²¤íŠ¸ ì„¤ì •
        self.stop_event.set()
        
        # í”„ë¡œì„¸ìŠ¤ë“¤ ìˆœì„œëŒ€ë¡œ ì¢…ë£Œ
        all_processes = [
            ("ìº¡ì²˜", self.capture_processes, 5),
            ("ë¸”ëŸ¬", self.blur_processes, 10),
            ("ì €ì¥", self.save_processes, 20),
            ("íŒŒì¼ì´ë™", self.file_move_processes, 15)
        ]
        
        for name, processes, timeout in all_processes:
            for proc in processes:
                if proc.is_alive():
                    logger.info(f"ğŸ”„ {name} í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ëŒ€ê¸°: {proc.name} (PID: {proc.pid})")
                    proc.join(timeout=timeout)
                    
                    if proc.is_alive():
                        logger.warning(f"âš ï¸ {name} í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ: {proc.name} (PID: {proc.pid})")
                        proc.terminate()
                        proc.join(timeout=2)
                        
                        if proc.is_alive():
                            logger.error(f"âŒ {name} í”„ë¡œì„¸ìŠ¤ ê°•ì œ í‚¬: {proc.name} (PID: {proc.pid})")
                            proc.kill()
                    else:
                        logger.info(f"âœ… {name} í”„ë¡œì„¸ìŠ¤ ì •ìƒ ì¢…ë£Œ: {proc.name} (PID: {proc.pid})")
        
        self.resource_monitor.stop_monitoring()
        logger.info("âœ… ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        í†µê³„ ì •ë³´ ë°˜í™˜
        
        Returns:
            Dict[str, Any]: ì¢…í•© í†µê³„ ì •ë³´
        """
        # í”„ë¡œì„¸ìŠ¤ë³„ í†µê³„ë¥¼ ì§‘ê³„
        total_received = sum(v for k, v in self.stats_dict.items() if k.endswith('_received'))
        total_processed = sum(v for k, v in self.stats_dict.items() if k.endswith('_processed'))
        total_saved = sum(v for k, v in self.stats_dict.items() if k.endswith('_saved'))
        total_moved = sum(v for k, v in self.stats_dict.items() if k.endswith('_moved'))
        total_lost = sum(v for k, v in self.stats_dict.items() if k.endswith('_lost'))
        
        # ìŠ¤ë ˆë“œë³„ ì—°ê²° ìƒíƒœ ìƒì„±
        connection_status = {}
        for i in range(self.config.thread_count):
            stream_id = f"stream_{i+1}"
            received = self.stats_dict.get(f'{stream_id}_received', 0)
            connection_status[i] = {
                'connected': received > 0,
                'last_frame_time': time.time() if received > 0 else 0,
                'start_time': time.time()
            }
        
        stats = {
            'received_frames': total_received,
            'processed_frames': total_processed,
            'saved_frames': total_saved,
            'moved_frames': total_moved,
            'lost_frames': total_lost,
            'error_frames': 0,
            'total_frames': total_received,
            'loss_rate': total_lost / max(total_received, 1) * 100,
            'processing_rate': total_processed / max(total_received, 1) * 100,
            'save_rate': total_saved / max(total_processed, 1) * 100,
            'move_rate': total_moved / max(total_saved, 1) * 100 if hasattr(self.config, 'two_stage_storage') and self.config.two_stage_storage else 0,
            'thread_count': self.config.thread_count,
            'queue_size': 0,
            'preview_queue_sizes': {0: self.preview_queue.qsize()},
            'blur_queue_size': self.blur_queue.qsize(),
            'save_queue_size': self.save_queue.qsize(),
            'file_move_queue_size': self.file_move_queue.qsize() if self.file_move_queue else 0,
            'connection_status': connection_status,
            'resource_stats': self.resource_monitor.get_current_stats(),
            'performance_stats': self.performance_profiler.get_all_profiles(),
            'two_stage_storage': hasattr(self.config, 'two_stage_storage') and self.config.two_stage_storage
        }
        
        return stats
    
    def get_preview_frame(self) -> Optional[Any]:
        """
        ë¯¸ë¦¬ë³´ê¸°ìš© í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
        
        Returns:
            Optional[Any]: ë¯¸ë¦¬ë³´ê¸° í”„ë ˆì„ (ì—†ìœ¼ë©´ None)
        """
        try:
            if hasattr(self.config, 'preview_enabled') and not self.config.preview_enabled:
                return None
                
            # ë¯¸ë¦¬ë³´ê¸° íì—ì„œ ìµœì‹  í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° (ë…¼ë¸”ë¡œí‚¹)
            frame_data = self.preview_queue.get_nowait()
            
            # íì— ìŒ“ì¸ ì˜¤ë˜ëœ í”„ë ˆì„ë“¤ ì œê±° (ìµœì‹  í”„ë ˆì„ë§Œ ìœ ì§€)
            while not self.preview_queue.empty():
                try:
                    newer_frame_data = self.preview_queue.get_nowait()
                    frame_data = newer_frame_data  # ë” ìƒˆë¡œìš´ í”„ë ˆì„ìœ¼ë¡œ êµì²´
                except queue.Empty:
                    break
            
            # í”„ë ˆì„ì€ (stream_id, frame, info) íŠœí”Œ í˜•íƒœë¡œ ì „ì†¡ë¨
            if isinstance(frame_data, tuple) and len(frame_data) >= 2:
                return frame_data[1]  # ì‹¤ì œ í”„ë ˆì„ ë°ì´í„° ë°˜í™˜
            else:
                return frame_data  # ë‹¨ì¼ í”„ë ˆì„ì¸ ê²½ìš°
            
        except queue.Empty:
            # íê°€ ë¹„ì–´ìˆìŒ - ì •ìƒì ì¸ ìƒí™©
            return None
        except Exception as e:
            logger.debug(f"ë¯¸ë¦¬ë³´ê¸° í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def get_preview_queue_size(self) -> int:
        """
        ë¯¸ë¦¬ë³´ê¸° í í¬ê¸° ë°˜í™˜
        
        Returns:
            int: í˜„ì¬ ë¯¸ë¦¬ë³´ê¸° íì— ìˆëŠ” í”„ë ˆì„ ìˆ˜
        """
        try:
            return self.preview_queue.qsize()
        except:
            return 0
    
    def get_thread_statistics(self, thread_id: int) -> Dict[str, Any]:
        """
        ìŠ¤ë ˆë“œë³„ í†µê³„ ë°˜í™˜
        
        Args:
            thread_id (int): ìŠ¤ë ˆë“œ ID
            
        Returns:
            Dict[str, Any]: ìŠ¤ë ˆë“œë³„ í†µê³„ ì •ë³´
        """
        stream_id = f"stream_{thread_id+1}"
        received = self.stats_dict.get(f'{stream_id}_received', 0)
        processed = self.stats_dict.get(f'{stream_id}_processed', 0)
        saved = self.stats_dict.get(f'{stream_id}_saved', 0)
        moved = self.stats_dict.get(f'{stream_id}_moved', 0)
        lost = self.stats_dict.get(f'{stream_id}_lost', 0)
        
        return {
            'received_frames': received,
            'processed_frames': processed,
            'saved_frames': saved,
            'moved_frames': moved,
            'lost_frames': lost,
            'error_frames': 0,
            'total_frames': received,
            'loss_rate': lost / max(received, 1) * 100,
            'processing_rate': processed / max(received, 1) * 100,
            'save_rate': saved / max(processed, 1) * 100,
            'move_rate': moved / max(saved, 1) * 100 if hasattr(self.config, 'two_stage_storage') and self.config.two_stage_storage else 0
        }
    
    def reset_statistics(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.frame_counter.reset()
        self.stats_dict.clear()
        logger.info("í†µê³„ ì´ˆê¸°í™”ë¨")