#!/bin/bash
# RTSP ì‹œë®¬ë ˆì´í„° v2 - AI íŒ¨í‚¤ì§€ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
# CUDA 12.1 + TensorRT 10.0 + PyTorch 2.5.1 ì„¤ì¹˜

set -e  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨

echo "ðŸš€ RTSP ì‹œë®¬ë ˆì´í„° v2 - AI íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹œìž‘"
echo "===================================================="

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# í•¨ìˆ˜ ì •ì˜
print_step() {
    echo -e "${BLUE}[ë‹¨ê³„ $1]${NC} $2"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

# GPU í™•ì¸
print_step "0" "GPU ë° CUDA í™˜ê²½ í™•ì¸"
if command -v nvidia-smi &> /dev/null; then
    echo "NVIDIA GPU ì •ë³´:"
    nvidia-smi --query-gpu=name,memory.total,driver_version,cuda_version --format=csv,noheader,nounits
    print_success "NVIDIA GPU ê°ì§€ë¨"
else
    print_warning "nvidia-smië¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. NVIDIA ë“œë¼ì´ë²„ë¥¼ í™•ì¸í•˜ì„¸ìš”."
fi

# ê°€ìƒí™˜ê²½ í™•ì¸
if [[ "$VIRTUAL_ENV" != "" ]]; then
    print_success "ê°€ìƒí™˜ê²½ í™œì„±í™”ë¨: $VIRTUAL_ENV"
else
    print_warning "ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê³„ì†í•˜ë ¤ë©´ yë¥¼ ìž…ë ¥í•˜ì„¸ìš”."
    read -p "ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        print_error "ì„¤ì¹˜ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
        exit 1
    fi
fi

# 1. ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
print_step "1" "ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜"
pip install --upgrade pip setuptools wheel
pip install opencv-python pillow numpy psutil GPUtil
print_success "ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"

# 2. PyTorch 2.5.1 + CUDA 12.1 ì„¤ì¹˜
print_step "2" "PyTorch 2.5.1 + CUDA 12.1 ì„¤ì¹˜"
pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 \
            --index-url https://download.pytorch.org/whl/cu121
print_success "PyTorch CUDA 12.1 ì„¤ì¹˜ ì™„ë£Œ"

# 3. ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ (cmake)
print_step "3" "ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ (cmake)"
if command -v cmake &> /dev/null; then
    print_success "cmakeê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìžˆìŠµë‹ˆë‹¤."
else
    echo "cmake ì„¤ì¹˜ ì¤‘... (sudo ê¶Œí•œ í•„ìš”)"
    sudo apt-get update -qq
    sudo apt-get install -y cmake
    print_success "cmake ì„¤ì¹˜ ì™„ë£Œ"
fi

# 4. ONNX ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜
print_step "4" "ONNX ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜"
pip install onnxsim==0.4.33 onnxruntime-gpu
print_success "ONNX íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"

# 5. TensorRT ì„¤ì¹˜ (NVIDIA PyPI ë ˆì§€ìŠ¤íŠ¸ë¦¬)
print_step "5" "TensorRT 10.0.1 ì„¤ì¹˜"
pip install tensorrt-cu12==10.0.1 \
            tensorrt-cu12-bindings==10.0.1 \
            tensorrt-cu12-libs==10.0.1 \
            --extra-index-url https://pypi.ngc.nvidia.com
print_success "TensorRT ì„¤ì¹˜ ì™„ë£Œ"

# 6. Ultralytics YOLO ìµœì‹  ë²„ì „ ì„¤ì¹˜
print_step "6" "Ultralytics YOLO ìµœì‹  ë²„ì „ ì„¤ì¹˜"
pip install --upgrade ultralytics
print_success "Ultralytics YOLO ì„¤ì¹˜ ì™„ë£Œ"

# 7. ì¶”ê°€ AI/ML íŒ¨í‚¤ì§€ ì„¤ì¹˜
print_step "7" "ì¶”ê°€ AI/ML íŒ¨í‚¤ì§€ ì„¤ì¹˜"
pip install scikit-image matplotlib
print_success "ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"

# 8. ì„¤ì¹˜ í™•ì¸ ë° í…ŒìŠ¤íŠ¸
print_step "8" "ì„¤ì¹˜ í™•ì¸ ë° í…ŒìŠ¤íŠ¸"

echo "ðŸ” ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ë²„ì „ í™•ì¸:"
echo "----------------------------------------"

# PyTorch í™•ì¸
python -c "import torch; print(f'PyTorch: {torch.__version__}')" 2>/dev/null || print_error "PyTorch ìž„í¬íŠ¸ ì‹¤íŒ¨"
python -c "import torch; print(f'CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}')" 2>/dev/null || print_error "CUDA í™•ì¸ ì‹¤íŒ¨"

# TensorRT í™•ì¸  
python -c "import tensorrt; print(f'TensorRT: {tensorrt.__version__}')" 2>/dev/null || print_error "TensorRT ìž„í¬íŠ¸ ì‹¤íŒ¨"

# ONNX í™•ì¸
python -c "import onnx; print(f'ONNX: {onnx.__version__}')" 2>/dev/null || print_error "ONNX ìž„í¬íŠ¸ ì‹¤íŒ¨"
python -c "import onnxruntime; print(f'ONNX Runtime: {onnxruntime.__version__}')" 2>/dev/null || print_error "ONNX Runtime ìž„í¬íŠ¸ ì‹¤íŒ¨"

# Ultralytics í™•ì¸
python -c "import ultralytics; print(f'Ultralytics: {ultralytics.__version__}')" 2>/dev/null || print_error "Ultralytics ìž„í¬íŠ¸ ì‹¤íŒ¨"

# GPU ëª¨ë‹ˆí„°ë§ í™•ì¸
python -c "import GPUtil; gpus = GPUtil.getGPUs(); print(f'GPU ëª¨ë‹ˆí„°ë§: {len(gpus)}ê°œ GPU ê°ì§€')" 2>/dev/null || print_error "GPUtil í™•ì¸ ì‹¤íŒ¨"

echo "----------------------------------------"

# 9. YOLO ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸ (ì„ íƒì )
echo
read -p "ðŸ¤– YOLO ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$|^$ ]]; then
    print_step "9" "YOLO ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸"
    python -c "
from ultralytics import YOLO
print('YOLOv8n ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...')
model = YOLO('yolov8n.pt')
print('âœ… YOLO ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ì„±ê³µ')
print(f'ëª¨ë¸ ì •ë³´: {model.info()}')
" 2>/dev/null && print_success "YOLO ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ" || print_warning "YOLO ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (ì¸í„°ë„· ì—°ê²° í™•ì¸)"
fi

# ì™„ë£Œ ë©”ì‹œì§€
echo
echo "===================================================="
print_success "ðŸŽ‰ AI íŒ¨í‚¤ì§€ ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
echo
echo "ðŸ“‹ ì„¤ì¹˜ëœ ì£¼ìš” íŒ¨í‚¤ì§€:"
echo "  â€¢ PyTorch 2.5.1 + CUDA 12.1"
echo "  â€¢ TensorRT 10.0.1"
echo "  â€¢ ONNX Runtime GPU"
echo "  â€¢ Ultralytics YOLO (ìµœì‹ )"
echo "  â€¢ GPUtil (GPU ëª¨ë‹ˆí„°ë§)"
echo
echo "ðŸš€ ì´ì œ rtsp_simulator_ffmpeg_v2.pyë¥¼ ì‹¤í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤:"
echo "   python rtsp_simulator_ffmpeg_v2.py"
echo
echo "ðŸ“Š GPU ìƒíƒœ í™•ì¸:"
nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv,noheader,nounits 2>/dev/null || echo "nvidia-smi ì‚¬ìš© ë¶ˆê°€"
echo "====================================================" 